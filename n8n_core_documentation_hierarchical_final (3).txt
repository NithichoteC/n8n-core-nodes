# Table of Contents
1. Triggers
  1.1. activationTrigger
  1.2. emailReadImap
  1.3. errorTrigger
  1.4. executeWorkflowTrigger
  1.5. localFileTrigger
  1.6. manualTrigger
  1.7. mcpServerTrigger
  1.8. n8nTrigger
  1.9. scheduleTrigger
  1.10. sseTrigger
  1.11. webhook
2. Data Transformation
  2.1. aggregate
  2.2. compression
  2.3. convertToFile
  2.4. crypt
  2.5. editFields
  2.6. extractFromFile
  2.7. html
  2.8. itemLists
  2.9. markdown
  2.10. merge
  2.11. moveBinaryData
  2.12. renameKeys
  2.13. set
  2.14. xml
3. Flow Control
  3.1. compareDatasets
  3.2. filter
  3.3. if
  3.4. limit
  3.5. removeDuplicates
  3.6. sort
  3.7. splitInBatches
  3.8. stopAndError
  3.9. switch
4. Code Execution
  4.1. code
5. Core Operations
  5.1. executeCommand
  5.2. executeWorkflow
  5.3. n8nNode
  5.4. respondToWebhook
6. Network
  6.1. graphQLRequest
  6.2. httpRequest
  6.3. mqtt
7. File Operations
  7.1. ftp
  7.2. readBinaryFile
  7.3. writeBinaryFile
8. Database
  8.1. redis
9. Communication
  9.1. sendEmail
10. Utility
  10.1. dateTime
  10.2. noOperation
  10.3. wait
11. AI / Langchain
  11.1. Chains
    11.1.1. basicLLMChain
    11.1.2. retrievalQAChain
    11.1.3. summarizationChain
    11.1.4. sentimentAnalysis
    11.1.5. textClassifier
  11.2. Agents
    11.2.1. agent
  11.3. Vector Stores
    11.3.1. simpleVectorStore
    11.3.2. pgVectorVectorStore
    11.3.3. pineconeVectorStore
    11.3.4. qdrantVectorStore
    11.3.5. supabaseVectorStore
    11.3.6. zepVectorStore
  11.4. Miscellaneous
    11.4.1. langChainCode

---

## 1.1. activationTrigger

# Activation Trigger Node (Deprecated)

**Warning:** The Activation Trigger node has been deprecated and replaced by the [n8n Trigger node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.n8ntrigger/) and the [Workflow Trigger node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.workflowtrigger/). Please refer to the documentation for these newer nodes for current functionality.

This node was previously used to trigger a workflow based on specific events within n8n or the workflow itself.

## Intended Use (Deprecated)

The Activation Trigger node was designed to initiate a workflow when one of the following events occurred:

*   **Activation**: The workflow containing the node was activated.
*   **Start**: The n8n instance started or restarted.
*   **Update**: The workflow containing the node was saved while it was active.

It was typically added directly to the workflow it was intended to monitor or react to, rather than requiring a separate workflow.

## Node Parameters (Deprecated)

*   **Events**: A selection of events that could trigger the node:
    *   **Activation**: Run when the workflow gets activated.
    *   **Start**: Run when n8n starts or restarts.
    *   **Update**: Run when the workflow gets saved while it's active.

*Source: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.activationtrigger/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.activationtrigger/)*

---

## 1.2. emailReadImap

# n8n Core Node: Email Trigger (IMAP)

## Overview

The Email Trigger (IMAP) node allows n8n workflows to be initiated when new emails arrive in a specified mailbox on an IMAP-compatible email server. It periodically checks the configured mailbox for new messages that match optional criteria and triggers the workflow for each matching email found.

This node requires credentials to connect to an IMAP server (like Gmail, Outlook/Office 365, or other providers supporting IMAP).

## Use Cases

*   Automating responses to specific incoming emails.
*   Extracting data or attachments from emails for further processing.
*   Creating tasks or records in other systems based on email content.
*   Filtering and forwarding emails based on complex rules.

## Node Parameters

### Credential to connect with

Select an existing IMAP credential or create a new one. This credential stores the necessary information (server address, port, username, password/app password) to connect securely to your email account via IMAP. Refer to the n8n documentation for specific guidance on creating [IMAP credentials](https://docs.n8n.io/integrations/builtin/credentials/imap/).

### Mailbox Name

Specify the exact name of the mailbox (folder) within your email account that the trigger should monitor. Common examples include `INBOX`, `Sent`, or custom folder names. The exact name is usually case-sensitive and depends on your email provider.

### Action

Determine what happens to the email on the server after n8n successfully processes it:

*   **None:** Leaves the email in its original state (e.g., unread).
*   **Mark as Read:** Marks the email as read on the server after processing.

### Download Attachments

A toggle switch to control whether the node should download attachments found in the email. Enabling this will include the attachment data (usually as binary data) in the node's output. Disable this if attachments are not needed, as downloading them consumes more resources and time.

### Format

Choose the desired format for the output data representing the email message:

*   **RAW:** Returns the complete, raw email source, including headers and body, typically encoded (e.g., base64url). Attachments are not directly accessible as binary data in this format.
*   **Resolved:** Provides a structured JSON output with parsed headers, body content (often in both plain text and HTML), and any attachments included as binary data properties if `Download Attachments` is enabled.
*   **Simple:** Returns a simplified JSON structure of the email. This format might not include inline attachments correctly.

## Node Options (Advanced)

### Custom Email Rules

Define specific criteria to filter which emails trigger the workflow. This uses the standard IMAP search criteria syntax (based on [node-imap's search function](https://github.com/mscdex/node-imap#connection-instance-methods)). Examples:

*   `["UNSEEN"]`: Only trigger for unread emails.
*   `[["FROM", "sender@example.com"]]`: Only trigger for emails from a specific sender.
*   `[["SUBJECT", "Urgent Report"]]`: Only trigger for emails with a specific subject.
*   `["UNSEEN", ["FROM", "user@domain.com"], ["SUBJECT", "Order Confirmation"]]`: Combine multiple criteria.

If left empty, the node typically fetches all messages in the specified mailbox (often combined with the "Mark as Read" action to avoid reprocessing).

### Force Reconnect Every Minutes

Specify an interval (in minutes) after which the node should forcefully close and re-establish the connection to the IMAP server. This can sometimes help maintain a stable connection, especially with servers that might time out idle connections.

## Output Data

Depending on the selected **Format**, the output data will contain information about the triggered email, such as:

*   Sender, recipients (To, Cc, Bcc)
*   Subject
*   Date/Time
*   Message Body (Text and/or HTML)
*   Message ID
*   Attachments (if downloaded, as binary data)
*   Raw email source (in RAW format)

---

## 1.3. errorTrigger

# Error Trigger Node

Use the Error Trigger node to initiate a dedicated error handling workflow when another linked workflow encounters an error.

## Functionality

When a primary workflow fails, and it has been configured to use an error workflow (via Workflow Settings > Error workflow), the Error Trigger node in the designated error workflow will activate. It receives details about the failed execution, including the error message, stack trace, the node where the error occurred, and information about the workflow and execution context.

## Usage

1.  **Create Error Workflow**: Start a new workflow with the Error Trigger node as the first node.
2.  **Save Error Workflow**: Give this workflow a descriptive name (e.g., "Global Error Handler") and save it. Activation is not required for error workflows.
3.  **Link Primary Workflow**: In the settings of the primary workflow you want to monitor, navigate to **Options > Settings**.
4.  **Select Error Workflow**: In the **Error workflow** dropdown, select the error workflow you just created.
5.  **Save Primary Workflow**: Save the changes to the primary workflow.

Now, if the primary workflow fails during an automatic execution, the linked error workflow will run, starting with the Error Trigger node.

**Important Notes:**

*   Error workflows only trigger for automatic executions (e.g., via Webhook, Schedule Trigger), not manual runs.
*   If a workflow contains an Error Trigger node, it defaults to using itself as its own error workflow.
*   You can use the [Stop And Error node](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.stopanderror/) in the primary workflow to intentionally trigger the error workflow with custom error details.

## Error Data Structure

The Error Trigger node receives JSON data containing details about the failure. The structure varies slightly depending on whether the error occurred in the trigger node itself or later in the workflow execution.

**Typical Error Data (Error after trigger):**

```json
[
  {
    "execution": {
      "id": "231", // ID of the failed execution (if saved)
      "url": "https://n8n.example.com/execution/231", // URL to the failed execution (if saved)
      "retryOf": "34", // ID of the original execution if this was a retry (optional)
      "error": {
        "message": "Example Error Message",
        "stack": "Stacktrace..."
      },
      "lastNodeExecuted": "Node With Error", // Name of the node that failed
      "mode": "manual" // Execution mode (e.g., manual, webhook)
    },
    "workflow": {
      "id": "1", // ID of the failed workflow
      "name": "Example Workflow" // Name of the failed workflow
    }
  }
]
```

**Trigger Error Data:**

If the error occurs within the trigger node itself, the `execution` object will contain less information, and a `trigger` object with error details will be present.

```json
{
  "trigger": {
    "error": {
      "context": {},
      "name": "WorkflowActivationError",
      "cause": {
        "message": "",
        "stack": ""
      },
      "timestamp": 1654609328787,
      "message": "",
      "node": { 
        // Details about the trigger node
      }
    },
    "mode": "trigger"
  },
  "workflow": {
    "id": "",
    "name": ""
  }
}
```

*Source: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.errortrigger/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.errortrigger/)*
*Related: [Error Handling Concepts](https://docs.n8n.io/flow-logic/error-handling/)*

---

## 1.4. executeWorkflowTrigger

# n8n Core Node: Execute Sub-workflow Trigger

## Overview

The Execute Sub-workflow Trigger node (also found as "When Executed by Another Workflow" when adding a trigger) allows one n8n workflow (the "sub-workflow") to be initiated or called by another n8n workflow (the "parent workflow"). This node must be the first node in the sub-workflow.

This mechanism is essential for modular workflow design within n8n, enabling users to:

*   **Reuse Logic:** Create common, reusable pieces of automation (like data enrichment, reporting, or error handling) as separate sub-workflows that can be called by multiple parent workflows, avoiding duplication of effort.
*   **Simplify Complexity:** Break down large, complex workflows into smaller, more manageable, and understandable sub-workflows. This improves maintainability and readability.

## Usage

This trigger node does not run on its own schedule or in response to external events. Instead, it activates *only* when called by either:

1.  An **Execute Sub-workflow** node in a parent workflow.
2.  A **Call n8n Workflow Tool** node within an AI Agent context (part of the LangChain/AI nodes).

### Creating the Sub-workflow

1.  **New Workflow:** Start by creating a new, blank workflow that will serve as your sub-workflow.
2.  **Add Trigger:** Add the "Execute Sub-workflow Trigger" node as the very first node.
3.  **Define Input Data (Input data mode):** Configure how the sub-workflow expects to receive data from the parent workflow:
    *   **Define using fields below:** Allows you to explicitly define the names and expected data types (String, Number, Boolean, JSON, etc.) for each input parameter the sub-workflow requires. When a parent workflow uses the Execute Sub-workflow node to call this sub-workflow, these defined fields will automatically appear as parameters to be filled in.
    *   **Define using JSON example:** Allows you to provide a sample JSON object representing the structure and data types of the expected input. This serves as a template for the parent workflow.
    *   **Accept all data:** The sub-workflow will accept any data passed by the parent workflow without predefined validation. The sub-workflow itself must handle potential variations or missing data.
4.  **Build Logic:** Add subsequent nodes to implement the desired functionality of the sub-workflow, using the data received via the trigger node.
5.  **Workflow Settings (Optional):** You can restrict which specific parent workflows are allowed to call this sub-workflow via the workflow's settings menu (**Options > Settings > This workflow can be called by**).
6.  **Save:** Save the sub-workflow. Ensure it has no errors, as errors will prevent parent workflows from successfully calling it.

### Calling the Sub-workflow (from a Parent Workflow)

1.  **Open Parent Workflow:** Go to the workflow from which you want to initiate the sub-workflow.
2.  **Add Execute Sub-workflow Node:** Add the "Execute Sub-workflow" node at the point where you want to call the sub-workflow.
3.  **Target Sub-workflow:** Configure the node to specify which sub-workflow to call. Options include:
    *   **By ID:** Select from a list of available workflows in your n8n instance or manually enter the sub-workflow's ID (found in its URL).
    *   **From File:** Load the sub-workflow's JSON definition from a local file.
    *   **JSON Parameter:** Paste the sub-workflow's JSON directly into the node.
    *   **By URL:** Specify the URL of the sub-workflow (less common).
4.  **Provide Input Data:** If the sub-workflow trigger was configured with "Define using fields below" or "Define using JSON example", corresponding input fields will appear in the Execute Sub-workflow node. Populate these fields, often using expressions to pass data from previous nodes in the parent workflow.
5.  **Save Parent Workflow:** Save the changes.

## Data Flow

When the parent workflow reaches the Execute Sub-workflow node:

1.  The data configured as input in the Execute Sub-workflow node is passed to the Execute Sub-workflow Trigger node in the sub-workflow.
2.  The sub-workflow executes its logic using the received data.
3.  The data output by the *last* node in the sub-workflow is automatically sent back to the Execute Sub-workflow node in the parent workflow.
4.  The parent workflow then continues its execution, using the data returned from the sub-workflow as the output of the Execute Sub-workflow node.

n8n provides links within the execution logs to easily navigate between the parent workflow's execution and the corresponding sub-workflow's execution for debugging purposes.

## Related Nodes

*   **Execute Sub-workflow:** The node used in a parent workflow to call a sub-workflow that starts with the Execute Sub-workflow Trigger.
*   **Call n8n Workflow Tool (AI):** An AI tool node that can call a sub-workflow.

---

## 1.5. localFileTrigger

# n8n Core Node: Local File Trigger

## Overview

The Local File Trigger node provides a mechanism to initiate an n8n workflow based on changes occurring within the local file system where the n8n instance is running. It actively monitors a specified file or folder and triggers the workflow when certain events happen, such as a file being added, modified, or deleted.

**Important Note:** This trigger node is **only available for self-hosted n8n instances**. It cannot be used with n8n Cloud due to the nature of accessing the underlying file system.

## Use Cases

This node is useful for scenarios where automation needs to react to file system events, such as:

*   Processing files dropped into a specific 'watch' folder.
*   Triggering a workflow when a configuration file is updated.
*   Initiating backups or cleanup tasks when files are deleted.
*   Monitoring log files for specific changes (though dedicated log monitoring might be more robust).

## Node Parameters

The primary configuration revolves around the **Trigger On** parameter, which determines whether the node monitors a single file or an entire folder.

### Trigger On: Changes to a Specific File

*   **File to Watch:** Specify the absolute path to the single file that the node should monitor. The workflow will trigger *only* when this specific file is modified.

### Trigger On: Changes Involving a Specific Folder

*   **Folder to Watch:** Specify the absolute path to the folder that the node should monitor.
*   **Watch for:** Select the type(s) of events within the specified folder that should trigger the workflow:
    *   **File Added:** Triggers when a new file appears in the folder.
    *   **File Changed:** Triggers when an existing file within the folder is modified.
    *   **File Deleted:** Triggers when a file is removed from the folder.
    *   **Folder Added:** Triggers when a new sub-folder is created within the watched folder.
    *   **Folder Deleted:** Triggers when a sub-folder is removed from the watched folder.
    You can select multiple event types.

## Node Options (Advanced)

Additional options allow for more refined control over the monitoring process:

*   **Include Linked Files/Folders:** If enabled, the node will also monitor symbolic links (symlinks) within the watched directory.
*   **Ignore:** Specify patterns for files or paths that should be *excluded* from triggering the workflow. This uses [Anymatch](https://github.com/micromatch/anymatch) syntax (similar to glob patterns). The pattern is tested against the full path, not just the filename.
    *   *Example (ignore specific file):* `**/myfile.log`
    *   *Example (ignore specific sub-directory):* `**/temp/**`
    *   *Example (ignore all hidden files):* `**/.*`
*   **Max Folder Depth:** Define how many levels deep into sub-folders the node should monitor for changes. A value of `0` means only the top-level folder is watched, `1` includes direct sub-folders, and so on. Leaving it blank or setting it to a high number implies watching recursively through all sub-folders.
*   **Use Polling:** This option relates to how the file system changes are detected. Polling periodically checks the file system status, which can be necessary in some environments (like certain network shares or virtualized file systems) where standard file system events might not work reliably. However, polling can be less efficient.

## Output Data

When the trigger activates, it typically outputs data about the event, including:

*   The type of event detected (e.g., `add`, `change`, `unlink`).
*   The full path to the file or folder that triggered the event.
*   Timestamps related to the event.

## Considerations for Docker/Self-Hosting

When running n8n in a Docker container, the **Folder to Watch** or **File to Watch** path must be specified *relative to the container's file system*. You need to ensure that the host directory you want to monitor is correctly mounted as a volume inside the n8n container, and then use the *container's path* to that mounted volume in the node configuration.

---

## 1.6. manualTrigger

# n8n-nodes-base.manualTrigger

The Manual Trigger node (internally `n8n-nodes-base.manualWorkflowTrigger`) serves as a starting point for workflows that are intended to be run manually by clicking the "Test Workflow" or "Execute Workflow" button in the n8n editor.

## Purpose

*   Acts as a placeholder trigger when no automatic trigger (like a webhook, schedule, or event trigger) is needed.
*   Allows for manual execution and testing of workflows.
*   A workflow must have at least one trigger node, and the Manual Trigger fulfills this requirement for manually executed workflows.

## Parameters

This node has no configurable parameters.

## JSON Example

This is a basic representation of the Manual Trigger node within a workflow's JSON structure. It typically has no specific parameters beyond the standard node properties.

```json
{
  "nodes": [
    {
      "parameters": {},
      "id": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
      "name": "Manual Trigger",
      "type": "n8n-nodes-base.manualWorkflowTrigger",
      "typeVersion": 1,
      "position": [
        800,
        300
      ]
    }
    // ... other nodes in the workflow
  ],
  "connections": {
    // ... connections originating from the Manual Trigger
  }
}
```

---

## 1.7. mcpServerTrigger

# n8n Core Node: MCP Server Trigger

## Overview

The MCP Server Trigger node transforms an n8n instance into a server compliant with the [Model Context Protocol (MCP)](https://mcp.microsoft.com/). This allows external MCP clients (like AI assistants or other MCP-compatible tools) to discover and utilize n8n tools and workflows.

Unlike standard n8n trigger nodes that initiate a linear workflow execution based on an event, the MCP Server Trigger acts as an interactive endpoint. It exposes a specific URL that MCP clients connect to. Once connected, clients can query the server for a list of available tools and then invoke specific tools, passing input data and receiving results.

Crucially, this trigger node does **not** connect to subsequent nodes in the main workflow sequence in the traditional way. Instead, it exclusively connects to and manages n8n **Tool** nodes (including the `Custom n8n Workflow Tool`, which allows exposing entire workflows as tools).

## How it Works

1.  **Exposes URL:** The node generates a unique URL (MCP URL) that acts as the server endpoint.
2.  **Client Connection:** MCP clients connect to this URL.
3.  **Tool Discovery:** Clients can request a list of available tools connected to the MCP Server Trigger.
4.  **Tool Invocation:** Clients can select a specific tool and send input data to it via the MCP connection.
5.  **Execution:** The MCP Server Trigger directs the request to the corresponding Tool node within n8n.
6.  **Result Return:** The Tool node executes its function (or runs the associated workflow if it's a `Custom n8n Workflow Tool`) and returns the result to the MCP Server Trigger, which then relays it back to the client.

Communication typically happens over HTTP using [Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events) for maintaining a persistent connection.

## Node Parameters

### MCP URL

Similar to the Webhook node, the MCP Server Trigger provides distinct URLs for development and production:

*   **Test URL:** Used when testing the workflow manually or using "Listen for Test Event". Interactions are visible in the editor.
*   **Production URL:** Used when the workflow is active. Interactions trigger executions visible in the execution history.

### Authentication

Secure the MCP endpoint by requiring authentication from connecting clients:

*   **Bearer Auth:** Requires a Bearer token in the `Authorization` header.
*   **Header Auth:** Requires a specific value in a custom HTTP header.

Credentials need to be configured in n8n's credential manager (typically using HTTP Header or Bearer Token credential types).

### Path

Defines the unique path segment for the MCP URL. n8n generates a random path by default, but it can be customized. Route parameters (`/:variable`) are also supported.

## Integration Examples

*   **Claude Desktop:** Can be connected via a gateway tool like `supergateway` (run using `npx`) which proxies SSE messages to the stdio-based interface Claude Desktop expects. Configuration involves specifying the command, MCP URL, and authentication headers in the Claude Desktop settings.

## Limitations and Considerations

*   **SSE Requirement:** The protocol relies heavily on Server-Sent Events, which require stable, persistent HTTP connections.
*   **Queue Mode / Multiple Replicas:** When running n8n in queue mode with multiple webhook processor replicas, issues can arise because SSE connections need to be handled by the *same* server instance. To mitigate this, all traffic to the MCP path (e.g., `/mcp/*`) must be routed (via ingress or load balancer configuration) to a single, dedicated webhook replica.
*   **Reverse Proxies (e.g., Nginx):** If n8n runs behind a reverse proxy, the proxy must be configured correctly to handle SSE. This typically involves disabling proxy buffering (`proxy_buffering off;`) for the MCP location block and potentially adjusting other headers (`Connection`, `gzip`, `chunked_transfer_encoding`) to ensure the SSE stream is not interrupted.

## Related Nodes

*   **Tool Nodes:** Various nodes designed to be used within AI Agents or exposed via MCP (e.g., Calculator Tool, SerpAPI Tool, Custom n8n Workflow Tool).
*   **MCP Client Tool:** Allows an n8n AI Agent to connect to *external* MCP servers to utilize their tools.

---

## 1.8. n8nTrigger

# n8n Core Node: n8n Trigger

## Overview

The n8n Trigger node is a specialized trigger designed to initiate a workflow based on internal events occurring within the n8n instance itself or related to the specific workflow containing the trigger. It allows you to automate actions in response to n8n's operational lifecycle events.

## Use Cases

This trigger is useful for meta-automation tasks, such as:

*   Sending notifications (e.g., via Slack or email) when a specific workflow is updated or activated.
*   Performing initialization tasks or checks whenever the n8n instance starts or restarts.
*   Logging workflow deployment activities.

## Node Parameters

### Events

This is the primary parameter, allowing you to select which specific n8n internal event(s) should activate the trigger. You can choose one or more of the following:

*   **Active Workflow Updated:** The workflow triggers whenever the *current* workflow (the one containing this trigger node) is saved/updated while it is active.
*   **Instance started:** The workflow triggers whenever the n8n instance itself starts up or restarts.
*   **Workflow Activated:** The workflow triggers whenever the *current* workflow is activated (i.e., switched from inactive to active).

## Output Data

When triggered, the node typically outputs data related to the event that occurred, such as:

*   The type of event (e.g., `workflow.updated`, `workflow.activated`, `instance.started`).
*   Information about the workflow involved (ID, name) if applicable.
*   Timestamp of the event.

---

## 1.9. scheduleTrigger

```json
{
  "nodes": [
    {
      "parameters": {
        "triggerTimes": {
          "item": [
            {
              "mode": "everyX", // Example 1: Trigger every 5 minutes
              "value": 5,
              "unit": "minutes"
            },
            {
              "mode": "everyDay", // Example 2: Trigger daily at 9:30 AM
              "hour": 9,
              "minute": 30
            },
            {
              "mode": "everyWeek", // Example 3: Trigger weekly on Monday at 3:00 PM
              "weekday": "1", // 0=Sunday, 1=Monday, ..., 6=Saturday
              "hour": 15,
              "minute": 0
            },
            {
              "mode": "cron", // Example 4: Custom Cron - Trigger at 6:00 AM on the first day of every month
              "cronExpression": "0 6 1 * *"
            }
          ]
        },
        "options": {
          "timezone": "America/New_York" // Specify the timezone for the schedule
        }
      },
      "id": "schedule-trigger-uuid",
      "name": "Schedule Trigger Examples",
      "type": "n8n-nodes-base.scheduleTrigger",
      "typeVersion": 1.1, // Use appropriate version, check docs if needed
      "position": [
        300,
        400
      ]
      // This node triggers the workflow based on a defined schedule.
      // It supports various modes: every X seconds/minutes/hours, daily, weekly, monthly, or custom Cron expressions.
      // Ensure the workflow is active for the schedule to run.
      // Timezone setting is crucial for accurate scheduling.
    }
    // Add subsequent nodes here to be executed on schedule
  ],
  "connections": {}
}
```

---

## 1.10. sseTrigger

# n8n Core Node: SSE Trigger

## Overview

The SSE Trigger node allows an n8n workflow to connect to a remote endpoint that provides data using the [Server-Sent Events (SSE)](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events) protocol. SSE is a standard web technology where a server can push data updates to a client over a single, long-lived HTTP connection.

This trigger node establishes a connection to the specified SSE endpoint and listens for incoming events. Each event received from the server initiates an execution of the n8n workflow.

## Use Cases

*   Receiving real-time updates from services that expose an SSE feed (e.g., stock tickers, live activity streams, monitoring systems).
*   Integrating with custom applications that push status updates via SSE.

## Node Parameters

### URL

This is the primary and only required parameter. Enter the full URL of the Server-Sent Events endpoint that the node should connect to and listen for events.

## Authentication

While the basic node parameters don't explicitly list authentication, SSE endpoints might require authentication via standard HTTP methods:

*   **Query Parameters:** Some services might expect API keys or tokens directly in the URL.
*   **HTTP Headers:** The endpoint might require specific headers like `Authorization` (e.g., `Authorization: Bearer YOUR_TOKEN`). Currently, the SSE Trigger node itself doesn't have built-in support for adding custom headers directly in its parameters. If headers are required, you might need to consider alternative approaches or check if newer n8n versions have added this capability. One potential workaround, though less ideal, could involve using a proxy that adds the required headers before forwarding the request to the actual SSE endpoint.

## Output Data

When an event is received from the SSE stream, the trigger node outputs data associated with that event. The structure typically includes:

*   `data`: The payload of the SSE message.
*   `event`: The event type specified in the SSE message (if any).
*   `id`: The event ID specified in the SSE message (if any).
*   `retry`: The reconnection time specified by the server (if any).

## Considerations

*   **Persistent Connection:** The node maintains an open HTTP connection to the SSE server. Ensure your n8n instance and network environment allow for such long-lived connections.
*   **Error Handling:** Implement error handling in your workflow to manage potential connection issues or errors from the SSE stream.

---

## 1.11. webhook

# Webhook node

Use the Webhook node to create webhooks, which can receive data from apps and services when an event occurs. It's a trigger node, which means it can start an n8n workflow. This allows services to connect to n8n and run a workflow.

You can use the Webhook node as a trigger for a workflow when you want to receive data and run a workflow based on the data. The Webhook node also supports returning the data generated at the end of a workflow. This makes it useful for building a workflow to process data and return the results, like an API endpoint.

The webhook allows you to trigger workflows from services that don't have a dedicated app trigger node.

## Workflow development process

n8n provides different **Webhook URL**s for testing and production. The testing URL includes an option to **Listen for test event**. Refer to Workflow development for more information on building, testing, and shifting your Webhook node to production.

## Node parameters

Use these parameters to configure your node.

### Webhook URLs

The Webhook node has two **Webhook URLs**: test and production. n8n displays the URLs at the top of the node panel.

Select **Test URL** or **Production URL** to toggle which URL n8n displays.

*   **Test**: n8n registers a test webhook when you select **Listen for Test Event** or **Test workflow**, if the workflow isn't active. When you call the webhook URL, n8n displays the data in the workflow.
*   **Production**: n8n registers a production webhook when you activate the workflow. When using the production URL, n8n doesn't display the data in the workflow. You can still view workflow data for a production execution: select the **Executions** tab in the workflow, then select the workflow execution you want to view.

### HTTP Method

The Webhook node supports standard HTTP Request Methods:

*   DELETE
*   GET
*   HEAD
*   PATCH
*   POST
*   PUT

> **Webhook max payload**
> The webhook maximum payload size is 16MB. If you're self-hosting n8n, you can change this using the endpoint environment variable `N8N_PAYLOAD_SIZE_MAX`.

### Path

By default, this field contains a randomly generated webhook URL path, to avoid conflicts with other webhook nodes.

You can manually specify a URL path, including adding route parameters. For example, you may need to do this if you use n8n to prototype an API and want consistent endpoint URLs.

The **Path** field can take the following formats:

*   `/:variable`
*   `/path/:variable`
*   `/:variable/path`
*   `/:variable1/path/:variable2`
*   `/:variable1/:variable2`

### Supported authentication methods

You can require authentication for any service calling your webhook URL. Choose from these authentication methods:

*   Basic auth
*   Header auth
*   JWT auth
*   None

Refer to Webhook credentials for more information on setting up each credential type.

### Respond

*   **Immediately**: The Webhook node returns the response code and the message **Workflow got started**.
*   **When Last Node Finishes**: The Webhook node returns the response code and the data output from the last node executed in the workflow.
*   **Using 'Respond to Webhook' Node**: The Webhook node responds as defined in the Respond to Webhook node.

### Response Code

Customize the HTTP response code that the Webhook node returns upon successful execution. Select from common response codes or create a custom code.

### Response Data

Choose what data to include in the response body:

*   **All Entries**: The Webhook returns all the entries of the last node in an array.
*   **First Entry JSON**: The Webhook returns the JSON data of the first entry of the last node in a JSON object.
*   **First Entry Binary**: The Webhook returns the binary data of the first entry of the last node in a binary file.
*   **No Response Body**: The Webhook returns without a body.

Applies only to **Respond > When Last Node Finishes**.

## Node options

Select **Add Option** to view more configuration options. The available options depend on your node parameters. Refer to the table for option availability.

*   **Allowed Origins (CORS)**: Set the permitted cross-origin domains. Enter a comma-separated list of URLs allowed for cross-origin non-preflight requests. Use `*` (default) to allow all origins.
*   **Binary Property**: Enabling this setting allows the Webhook node to receive binary data, such as an image or audio file. Enter the name of the binary property to write the data of the received file to.
*   **Ignore Bots**: Ignore requests from bots like link previewers and web crawlers.
*   **IP(s) Whitelist**: Enable this to limit who (or what) can invoke a Webhook trigger URL. Enter a comma-separated list of allowed IP addresses. Access from IPs outside the whitelist throws a 403 error. If left blank, all IP addresses can invoke the webhook trigger URL.
*   **No Response Body**: Enable this to prevent n8n sending a body with the response.
*   **Raw Body**: Specify that the Webhook node will receive data in a raw format, such as JSON or XML.
*   **Response Content-Type**: Choose the format for the webhook body.
*   **Response Data**: Send custom data with the response.
*   **Response Headers**: Send extra headers in the Webhook response. Refer to MDN Web Docs | Response header to learn more about response headers.
*   **Property Name**: by default, n8n returns all available data. You can choose to return a specific JSON key, so that n8n returns the value.

## Templates and examples

Browse Webhook node documentation integration templates, or search all templates

## Common issues

For common questions or issues and suggested solutions, refer to Common issues.

---

## 2.1. aggregate

# Aggregate Node

Use the Aggregate node to group data from separate items, or portions of items, into individual items. This is useful for consolidating information spread across multiple workflow items.

## Node Parameters

The primary configuration involves selecting the aggregation method:

*   **Individual Fields**: Aggregate specific fields from input items separately.
*   **All Item Data**: Aggregate all data from input items into a single list within a specified field.

### Individual Fields Parameters

*   **Input Field Name**: Specify the name of the field in the input items whose values you want to aggregate.
*   **Rename Field**: (Toggle) Allows renaming the aggregated field in the output. This is mandatory if aggregating multiple fields.
    *   **Output Field Name**: (Visible if Rename Field is on) The desired name for the aggregated field in the output item.

### All Item Data Parameters

*   **Put Output in Field**: Specify the name of the field in the output item where the aggregated list of all item data will be stored.
*   **Include**: Control which fields are included in the aggregated data:
    *   **All fields**: Include all fields from the input items.
    *   **Specified Fields**: Include only the fields listed in the **Fields To Include** parameter (comma-separated).
    *   **All Fields Except**: Include all fields *except* those listed in the **Fields To Exclude** parameter (comma-separated).

## Node Options

Additional options provide finer control over the aggregation process:

*   **Disable Dot Notation**: (Available for Individual Fields) If turned on, prevents referencing nested fields using dot notation (e.g., `parent.child`). Defaults to off (allowed).
*   **Merge Lists**: (Available for Individual Fields) If the input field contains lists, turning this on merges them into a single flat list in the output, instead of a list of lists.
*   **Include Binaries**: (Available for both types) If turned on, includes binary data from the input items in the aggregated output.
*   **Keep Missing And Null Values**: (Available for Individual Fields) If turned on, includes a `null` entry in the output list when an input item has a missing or null value for the specified field. If off (default), missing/null values are ignored.

## Related Resources

For a deeper understanding of how data is structured and flows within n8n, refer to the official documentation on [data structure and data flow](https://docs.n8n.io/data/data-structure/).

*Source: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.aggregate/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.aggregate/)*

---

## 2.2. compression

# Compression Node

Use the Compression node to compress and decompress files within your n8n workflows. It supports both Zip and Gzip formats.

## Operations

The node offers two main operations:

*   **Compress**: Creates a compressed archive (Zip or Gzip) from one or more input binary files.
*   **Decompress**: Extracts files from an existing compressed archive (Zip or Gzip).

## Node Parameters

Parameters depend on the selected operation.

### Compress Parameters

*   **Input Binary Field(s)**: Specify the name(s) of the input field(s) containing the binary file data to be compressed. Use a comma-separated list for multiple files.
*   **Output Format**: Choose the desired compression format: **Zip** or **Gzip**.
*   **File Name**: Define the name for the resulting compressed file.
*   **Put Output File in Field**: Specify the name of the output field where the compressed binary file data will be placed.

### Decompress Parameters

*   **Input Binary Field(s)**: Specify the name(s) of the input field(s) containing the compressed binary file data to be decompressed. Use a comma-separated list for multiple files.
*   **Output Prefix**: (Optional) Add a prefix to the names of the extracted files.
*   **Put Output File in Field**: Specify the name of the output field where the decompressed binary file data will be placed. If decompressing multiple files, n8n will output multiple items, each containing one decompressed file in this field.

## AI Tool Capability

This node can be utilized as an AI tool within an AI agent, allowing parameters to be configured dynamically based on AI directives.

*Source: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.compression/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.compression/)*

---

## 2.3. convertToFile

# n8n Core Node: Convert to File

## Overview

The Convert to File node (`n8n-nodes-base.converttofile`) is a core utility node that transforms incoming JSON data into a specified file format, outputting the result as binary data attached to the item. It replaced part of the functionality of the deprecated Spreadsheet File node (from v1.21.0 onwards).

## Functionality

This node takes structured JSON data from input items and converts it into a binary file format like CSV, XLSX, JSON, HTML, ICS (iCalendar), ODS, RTF, or plain text. It can also convert a Base64 encoded string directly into a binary file.

## Operations

The node's behavior is determined by the selected `Operation`:

1.  **Convert to CSV:** Creates a Comma Separated Values file.
    *   `Put Output File in Field`: Specifies the output binary property name (default: `data`).
    *   Options:
        *   `File Name`: Name for the output file (e.g., `output.csv`).
        *   `Header Row`: (Boolean) Include the keys from the first item as a header row.

2.  **Convert to HTML:** Generates an HTML table from the input data.
    *   `Put Output File in Field`: Output binary property name.
    *   Options:
        *   `File Name`: Name for the output file (e.g., `report.html`).
        *   `Header Row`: (Boolean) Use keys as table headers (`<th>`).

3.  **Convert to ICS:** Creates an iCalendar (.ics) file for calendar events.
    *   `Put Output File in Field`: Output binary property name.
    *   `Event Title`: Field containing the event title.
    *   `Start`: Field containing the event start date/time.
    *   `End`: Field containing the event end date/time.
    *   `All Day`: (Boolean) Mark as an all-day event.
    *   Options: `File Name`, `Attendees` (Name, Email, RSVP), `Busy Status`, `Calendar Name`, `Description`, `Geolocation`, `Location`, `Recurrence Rule` (RRULE), `Organizer`, `Sequence`, `Status`, `UID`, `URL`, `Use Workflow Timezone`.

4.  **Convert to JSON:** Outputs the input JSON data as a .json file.
    *   `Mode`: `All Items to One File` (creates an array in the file) or `Each Item to Separate File` (creates one file per input item).
    *   Options:
        *   `File Name`: Name for the output file(s) (e.g., `data.json`).
        *   `Format`: (Boolean) Pretty-print the JSON for readability.
        *   `Encoding`: Character encoding (default: `utf8`).

5.  **Convert to ODS:** Creates an OpenDocument Spreadsheet (.ods) file.
    *   `Put Output File in Field`: Output binary property name.
    *   Options:
        *   `File Name`: Name for the output file (e.g., `spreadsheet.ods`).
        *   `Compression`: (Boolean) Compress the output file.
        *   `Header Row`: (Boolean) Use keys as header row.
        *   `Sheet Name`: Name for the spreadsheet sheet.

6.  **Convert to RTF:** Creates a Rich Text Format (.rtf) file.
    *   `Put Output File in Field`: Output binary property name.
    *   Options:
        *   `File Name`: Name for the output file (e.g., `document.rtf`).
        *   `Header Row`: (Boolean) Include keys as a header row.

7.  **Convert to Text File:** Creates a plain text file from a specified input field.
    *   `Text Input Field`: The JSON field containing the string to write to the file.
    *   Options:
        *   `File Name`: Name for the output file (e.g., `notes.txt`).
        *   `Encoding`: Character encoding (default: `utf8`).

8.  **Convert to XLS:** Creates a legacy Microsoft Excel (.xls) file.
    *   `Put Output File in Field`: Output binary property name.
    *   Options:
        *   `File Name`: Name for the output file (e.g., `legacy_sheet.xls`).
        *   `Header Row`: (Boolean) Use keys as header row.
        *   `Sheet Name`: Name for the spreadsheet sheet.

9.  **Convert to XLSX:** Creates a modern Microsoft Excel (.xlsx) file.
    *   `Put Output File in Field`: Output binary property name.
    *   Options:
        *   `File Name`: Name for the output file (e.g., `report.xlsx`).
        *   `Compression`: (Boolean) Compress the output file.
        *   `Header Row`: (Boolean) Use keys as header row.
        *   `Sheet Name`: Name for the spreadsheet sheet.

10. **Move Base64 String to File:** Decodes a Base64 encoded string from a JSON field into a binary file.
    *   `Base64 Input Field`: The JSON field containing the Base64 string.
    *   Options:
        *   `File Name`: Name for the output file.
        *   `MIME Type`: The MIME type of the decoded file (e.g., `image/png`, `application/pdf`).

## Use Cases

*   Generating reports in CSV, XLSX, or ODS format from workflow data.
*   Creating JSON files for backup or transfer.
*   Generating plain text files.
*   Creating iCalendar files to send meeting invites.
*   Decoding Base64 encoded files received from APIs.
*   Preparing files before uploading them to storage or sending as attachments.

## Related Nodes

*   **Extract From File:** The counterpart node for reading data *from* files into JSON.
*   **Read/Write Files from Disk:** For interacting with the local filesystem where n8n is running.
*   **Move Binary Data:** For moving data between JSON and binary properties without format conversion.

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.converttofile/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.converttofile/)*

---

## 2.4. crypt

# Crypto Node

Use the Crypto node to perform various cryptographic operations within your n8n workflows, such as generating random strings, hashing data, creating HMACs, and signing strings.

## Actions

The Crypto node supports the following actions:

*   **Generate**: Creates a random string based on specified encoding (ASCII, BASE64, HEX, UUID).
*   **Hash**: Computes a hash (MD5, SHA256, SHA3-256, SHA3-384, SHA3-512, SHA385, SHA512) of a given text value or binary file data. The output can be encoded in BASE64 or HEX.
*   **Hmac**: Generates a Hash-based Message Authentication Code (HMAC) using a specified hash algorithm (MD5, SHA256, SHA3-256, SHA3-384, SHA3-512, SHA385, SHA512) and a secret key. It can operate on text values or binary file data, with output encoded in BASE64 or HEX.
*   **Sign**: Signs a string value using a private key and a specified algorithm. The output signature can be encoded in BASE64 or HEX.

## Node Parameters

Parameters vary depending on the selected action.

### Generate Parameters

*   **Property Name**: The name of the output field where the generated random string will be stored.
*   **Type**: The encoding format for the generated string (ASCII, BASE64, HEX, or UUID).

### Hash Parameters

*   **Type**: The hashing algorithm to use (e.g., MD5, SHA256).
*   **Binary File**: A toggle to indicate if the input data is from a binary file (true) or a text value (false).
    *   **Value**: (Visible if Binary File is false) The text string to hash.
    *   **Binary Property Name**: (Visible if Binary File is true) The name of the binary property containing the data to hash.
*   **Property Name**: The name of the output field for the resulting hash.
*   **Encoding**: The encoding for the output hash (BASE64 or HEX).

### Hmac Parameters

*   **Binary File**: A toggle to indicate if the input data is from a binary file (true) or a text value (false).
    *   **Value**: (Visible if Binary File is false) The text string to apply HMAC to.
    *   **Binary Property Name**: (Visible if Binary File is true) The name of the binary property containing the data.
*   **Type**: The hashing algorithm to use for HMAC (e.g., MD5, SHA256).
*   **Property Name**: The name of the output field for the resulting HMAC.
*   **Secret**: The secret key to use for generating the HMAC.
*   **Encoding**: The encoding for the output HMAC (BASE64 or HEX).

### Sign Parameters

*   **Value**: The string value to sign.
*   **Property Name**: The name of the output field for the resulting signature.
*   **Algorithm Name or ID**: The signing algorithm to use (selected from a list or specified via an expression).
*   **Encoding**: The encoding for the output signature (BASE64 or HEX).
*   **Private Key**: The private key required for signing the string.

## AI Tool Capability

This node can be utilized as an AI tool within an AI agent, allowing many parameters to be configured dynamically based on AI directives.

## Examples

Refer to the official n8n documentation for workflow examples demonstrating how to:
*   Generate a random string.
*   Hash text or a file.
*   Create an HMAC for text or a file.
*   Sign a string.

*Source: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.crypto/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.crypto/)*

---

## 2.5. editFields

# Edit Fields (Set) Node

Use the Edit Fields node (`n8n-nodes-base.set`), often referred to as the Set node, to add, modify, or overwrite data fields within your n8n workflow items. It is a fundamental node for manipulating the structure and content of your workflow data.

## Node Parameters

*   **Mode**: Determines how you define the fields to set:
    *   **Manual Mapping**: Use a graphical interface to define field names and values. You can drag and drop values from the input panel or manually enter fixed values or expressions.
        *   **Fixed/Expressions Toggle**: For each field name and value, you can switch between entering a fixed string/number or using an n8n expression.
    *   **JSON Output**: Define the fields and values to add or overwrite using a JSON object. This allows for more complex structures and the use of expressions within the JSON.
*   **Fields to Set** (Manual Mapping Mode): Define the fields to add or modify:
    *   **Name**: The name of the field to create or overwrite. Supports dot notation by default (e.g., `customer.address.city`) unless disabled in options.
    *   **Value**: The value to assign to the field. Can be a fixed value or an expression.
    *   Click **Add Field** to define multiple fields.
*   **JSON Output** (JSON Output Mode): Enter the JSON object containing the fields and values to merge into the input data. You can use expressions within the JSON string values (e.g., `"userId": "{{ $json.id }}"`).
*   **Keep Only Set Fields**: If enabled, only the fields defined in this node will be present in the output item; all original input fields not explicitly set will be discarded.
*   **Include in Output**: Choose which input data fields (if any) should be merged with the newly set fields in the output. Options typically include `All Input Fields`, `None`, or specific selections.

## Node Options

*   **Include Binary Data**: If the input data contains binary properties, choose whether to include them in the output.
*   **Ignore Type Conversion Errors** (Manual Mapping only): If enabled, n8n will attempt to proceed even if there are data type mismatches during mapping, potentially leading to unexpected results.
*   **Support Dot Notation** (Manual Mapping only): Controls whether field names entered in the **Name** field are interpreted using dot notation to create nested objects (default: on). If off, a name like `customer.address` creates a field literally named `customer.address` instead of a nested structure.

## Use Cases

*   **Adding Static Values**: Adding fixed information like status flags, timestamps, or identifiers to items.
*   **Renaming Fields**: Copying a value from an old field name to a new field name (often used before a `Rename Keys` node if complex logic is needed).
*   **Restructuring Data**: Creating new nested objects or arrays from existing flat data.
*   **Calculating Values**: Using expressions in the **Value** field to compute new values based on input data.
*   **Preparing Data for Other Nodes**: Formatting data into the specific structure required by subsequent nodes (e.g., databases, APIs).
*   **Simplifying Output**: Using **Keep Only Set Fields** to remove unnecessary data before the end of a workflow.

*Source: Based on the official documentation page [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.set/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.set/)*

---

## 2.6. extractFromFile

# n8n Core Node: Extract From File

## Overview

The Extract From File node (`n8n-nodes-base.extractfromfile`) is a core utility node used to read data from various file formats stored as binary data within an n8n item and convert that data into a structured JSON format. It is the counterpart to the Convert to File node and replaced part of the functionality of the deprecated Spreadsheet File node (from v1.21.0 onwards).

## Functionality

This node takes an item with binary data (e.g., a file downloaded via HTTP Request, received via Webhook, or read from disk) and parses its content based on the selected file format, outputting the extracted data as JSON. This makes the file content accessible for manipulation and use in subsequent workflow nodes.

## Operations

The node's parsing logic depends on the selected `Operation`, which should match the format of the input binary file:

1.  **Extract From CSV:** Parses Comma Separated Values data into JSON objects, typically one per row.
2.  **Extract From HTML:** Extracts data from HTML files, often requiring CSS selectors to target specific elements (similar to the HTML node).
3.  **Extract From JSON:** Parses a binary file containing JSON data into usable JSON within the n8n item.
4.  **Extract From ICS:** Parses iCalendar (.ics) files, extracting event details into JSON.
5.  **Extract From ODS:** Parses OpenDocument Spreadsheet (.ods) files into JSON, usually representing rows and columns.
6.  **Extract From PDF:** Extracts text content from Portable Document Format (.pdf) files.
7.  **Extract From RTF:** Parses Rich Text Format (.rtf) files, extracting text content.
8.  **Extract From Text File:** Reads the content of a plain text file into a JSON field.
9.  **Extract From XLS:** Parses legacy Microsoft Excel (.xls) files into JSON.
10. **Extract From XLSX:** Parses modern Microsoft Excel (.xlsx) files into JSON.
11. **Move File to Base64 String:** Converts the input binary data into a Base64 encoded string and places it in a JSON field.

## Node Parameters

*   **Operation:** Select the format of the input file (CSV, PDF, XLSX, etc.).
*   **Input Binary Field:** The name of the binary property on the input item that contains the file data (defaults to `data`).
*   **Destination Output Field:** (Available for JSON, ICS, Text File, Base64 operations) The name of the JSON field where the extracted data or Base64 string will be placed.
*   **Options (Vary by Operation):** Specific operations have additional options:
    *   **CSV/Spreadsheets:** Header Row (Boolean), Sheet Name/Index, Cell Range, etc.
    *   **PDF:** Extract Text Only, etc.
    *   **HTML:** CSS Selectors, Output Format, etc.
    *   **Text/JSON/Base64:** Encoding (e.g., `utf8`).

## Use Cases

*   Reading data from uploaded CSV or Excel files.
*   Parsing JSON data stored in files.
*   Extracting text content from PDF or RTF documents for analysis or processing.
*   Reading configuration or data from text files.
*   Converting binary files (like images or documents) into Base64 strings for embedding in APIs or other formats.
*   Processing calendar event data from .ics files.

## Example Scenario: Reading a CSV File

1.  **Webhook Node:** Configured to receive a file upload (with Raw Body enabled) and outputs binary data in the `data` property.
2.  **Extract From File Node:**
    *   Operation: `Extract From CSV`
    *   Input Binary Field: `data`
    *   Options: `Header Row` enabled.
3.  **(Subsequent Nodes):** Process the resulting JSON items, where each item represents a row from the CSV file with keys derived from the header row.

## Considerations

*   **Input Format:** Ensure the selected `Operation` matches the actual format of the binary file.
*   **Binary Data:** The node expects the input item to have a valid binary property specified in `Input Binary Field`.
*   **Large Files:** Processing very large files might consume significant memory or time.
*   **PDF Extraction:** PDF text extraction quality can vary depending on the PDF structure and encoding.
*   **Webhook Configuration:** When receiving files via Webhook, ensure the `Raw Body` option is enabled for the Webhook node to output the binary data correctly.

## Related Nodes

*   **Convert to File:** The counterpart node for converting JSON data *into* various file formats.
*   **Read Binary File:** Reads a file from the local filesystem into binary data.
*   **HTTP Request:** Can download files, outputting binary data.
*   **Webhook:** Can receive file uploads, outputting binary data.

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.extractfromfile/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.extractfromfile/)*

---

## 2.7. html

# HTML Node

The HTML node (`n8n-nodes-base.html`) provides operations to help you work with HTML in n8n. It replaces the older HTML Extract node from version 0.213.0 onwards.

**Security Note:** When using the `Generate HTML template` operation, be cautious with untrusted inputs to avoid potential [XSS (cross-site scripting)](https://owasp.org/www-community/attacks/Cross_Site_Scripting_(XSS)) vulnerabilities.

## Operations

*   **Generate HTML template**: Creates an HTML template using standard HTML, CSS (`<style>`), JavaScript (`<script>`, not executed by n8n), and n8n expressions (`{{ }}`).
*   **Extract HTML content**: Extracts specific content from HTML source (provided as JSON property or binary file) using CSS selectors.
*   **Convert to HTML Table**: Converts incoming item data into an HTML table.

## Operation Details

### Generate HTML template

*   **HTML Template**: Text area to write the HTML template. Supports standard HTML, CSS, non-executed JS, and n8n expressions.

### Extract HTML Content

*   **Source Data**: Choose `JSON` (specify **JSON Property** containing HTML string/array) or `Binary` (specify **Input Binary Field** containing HTML file data).
*   **Extraction Values**: Define one or more extractions:
    *   **Key**: Name for the extracted data field.
    *   **CSS Selector**: The CSS selector to target the desired element(s).
    *   **Return Value**: What to extract:
        *   `Attribute`: Returns the value of a specified **Attribute** (e.g., `href`, `src`, `class`).
        *   `HTML`: Returns the inner HTML of the element.
        *   `Text`: Returns the text content. Can specify **Skip Selectors** (comma-separated) to exclude text from certain child elements.
        *   `Value`: Returns the value of form elements (`input`, `select`, `textarea`).
    *   **Return Array**: (Toggle) If multiple elements match the selector, return results as an array (on) or a single concatenated string (off).
*   **Options**:
    *   **Trim Values**: (Toggle) Remove leading/trailing whitespace and newlines.
    *   **Clean Up Text**: (Toggle) Remove leading/trailing whitespace, collapse multiple spaces to one, remove line breaks.

### Convert to HTML Table

*   **Options**:
    *   **Capitalize Headers**: (Toggle) Capitalize `<th>` content.
    *   **Custom Styling**: (Toggle) Enable custom attributes below.
    *   **Caption**: Add a `<caption>` to the table.
    *   **Table Attributes**: Add attributes to the `<table>` tag (e.g., `style="border: 1px solid black;"`).
    *   **Header Attributes**: Add attributes to `<th>` tags.
    *   **Row Attributes**: Add attributes to `<tr>` tags.
    *   **Cell Attributes**: Add attributes to `<td>` tags.

*Source: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.html/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.html/)*

---

## 2.8. itemLists

# Item Lists Node

Use the Item Lists node (`n8n-nodes-base.itemlists`) to perform various operations on arrays (lists) within your JSON data. This node allows you to manipulate lists of items effectively.

## Operations

The Item Lists node supports several operations, including:

*   **Append**: Adds items from one list to the end of another list.
*   **Concatenate**: Combines multiple lists into a single list.
*   **Count**: Returns the number of items in a list.
*   **Distinct**: Removes duplicate items from a list.
*   **Filter**: Selects items from a list based on specified criteria.
*   **Get Item**: Retrieves a specific item from a list based on its index.
*   **Get Items**: Retrieves a range of items from a list based on start and end indices.
*   **Join**: Combines the elements of a list into a single string, separated by a specified delimiter.
*   **Limit**: Returns a specified number of items from the beginning or end of a list.
*   **Reverse**: Reverses the order of items in a list.
*   **Slice**: Extracts a portion of a list based on start and end indices.
*   **Sort**: Sorts the items in a list based on specified criteria (e.g., alphabetically, numerically).
*   **Sum**: Calculates the sum of numerical values in a list.
*   **Union**: Combines items from multiple lists, removing duplicates.
*   *... and potentially others depending on the n8n version.*

## Parameters

Parameters vary depending on the selected **Operation**.

Common parameters include:

*   **Field To Operate On**: The JSON key containing the list (array) you want to manipulate.
*   **Output Field Name**: (Optional) The name for the new field containing the result of the operation. If left empty, the original field is overwritten.
*   **Other Fields**: Specific parameters required for the chosen operation (e.g., the list to append, the index to retrieve, the delimiter for joining, sorting criteria).

## Use Cases

*   **Data Cleaning**: Removing duplicate entries from a list.
*   **Data Aggregation**: Combining results from multiple sources into a single list.
*   **Data Extraction**: Pulling specific elements or ranges from an array.
*   **Data Formatting**: Joining list elements into a string for display or further processing.
*   **Looping Preparation**: Sorting or filtering lists before processing them in a loop (e.g., using Split In Batches).

*Source: Based on the official documentation page structure and common list operations.*

---

## 2.9. markdown

# Markdown Node

The Markdown node (`n8n-nodes-base.markdown`) converts text between Markdown and HTML formats.

## Operations (Modes)

*   **Markdown to HTML**: Converts input Markdown text to HTML.
*   **HTML to Markdown**: Converts input HTML text to Markdown.

## Node Parameters

*   **Mode**: Select either `Markdown to HTML` or `HTML to Markdown`.
*   **HTML** / **Markdown**: Input field for the text to be converted (field name changes based on selected Mode).
*   **Destination Key**: The field name where the converted output will be stored (e.g., `convertedText`, `level1.output`).

## Node Options

Options vary depending on the selected Mode and allow fine-tuning the conversion process (e.g., handling specific Markdown flavors, HTML tags, etc.). Refer to the official documentation for detailed options for each mode.

*   **Markdown to HTML Options**: Governs how Markdown is parsed and rendered as HTML (uses [Showdown](https://github.com/showdownjs/showdown), supports GitHub Flavored Markdown extensions via options).
*   **HTML to Markdown Options**: Governs how HTML is parsed and converted back to Markdown (uses [node-html-markdown](https://github.com/crito/node-html-markdown)).

## Use Cases

*   Generating HTML reports or emails from Markdown text.
*   Converting HTML content (e.g., from web scraping) into Markdown for storage or further processing.
*   Standardizing text formats within a workflow.

*Source: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.markdown/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.markdown/)*

---

## 2.10. merge

# n8n Core Node: Merge

## Overview

The Merge node (`n8n-nodes-base.merge`) is a crucial core node for controlling workflow execution flow and combining data from multiple incoming branches (streams). It waits until it receives data from all connected input branches before executing and passing data onwards.

*Note:* This node was significantly updated in n8n version 0.194.0. Support for more than two inputs and the SQL Query mode were added in version 1.49.0.

## Functionality

The primary function is to consolidate data streams that may have diverged earlier in the workflow (e.g., after an If node or parallel processing paths). It offers various modes to determine precisely how the data from different inputs should be combined or selected.

## Modes of Operation

### 1. Append

*   **Purpose:** Concatenates items from all inputs sequentially.
*   **Behavior:** Outputs items from Input 1, followed by items from Input 2, and so on.
*   **Parameters:**
    *   `Number of Inputs`: Specifies how many input branches the node should wait for (minimum 2).

### 2. Combine

*   **Purpose:** Merges items from different inputs based on specific criteria.
*   **Parameters:**
    *   `Combine By`: Determines the merging logic:
        *   **Matching Fields:** Merges items where specified key fields match across inputs.
            *   `Fields to Match (Input 1)`: Key field from the first input.
            *   `Fields to Match (Input 2)`: Key field from the second input (and subsequent inputs if >2).
            *   `Output Type`: Controls which items are included (similar to SQL joins):
                *   `Keep Matches` (Inner Join): Only outputs merged items where keys match.
                *   `Keep Non-Matches`: Outputs only items that *don't* have a match in the other input(s).
                *   `Keep Everything` (Full Outer Join): Outputs matched merged items AND unmatched items from all inputs.
                *   `Enrich Input 1` (Left Join): Outputs all items from Input 1, adding data from matching items in other inputs.
                *   `Enrich Input 2` (Right Join): Outputs all items from Input 2, adding data from matching items in other inputs (extends to Input 3, etc.).
        *   **Position:** Merges items based on their index (position) in each input stream (item 0 from Input 1 merges with item 0 from Input 2, etc.).
        *   **All Possible Combinations:** Creates an output item for every possible pairing of items between the inputs (Cartesian product).

### 3. SQL Query (v1.49.0+)

*   **Purpose:** Allows writing a custom SQL query using AlaSQL syntax to merge data.
*   **Behavior:** Treats incoming data streams as tables named `input1`, `input2`, etc.
*   **Parameters:**
    *   `SQL Query`: The SQL query to execute (e.g., `SELECT * FROM input1 JOIN input2 ON input1.id = input2.user_id`).

### 4. Choose Branch

*   **Purpose:** Selects one specific input branch to pass through, discarding data from others. Still waits for all inputs before executing.
*   **Parameters:**
    *   `Output`: Choose which input's data to output (`Input 1 Data`, `Input 2 Data`, etc.) or `A Single, Empty Item`.

## Combine Mode Options

These options refine the behavior when `Mode` is set to `Combine`:

*   **Clash Handling:** Determines how to handle fields with the same name in different inputs during merging.
    *   `When Field Values Clash`: `Prioritize Input 2` (Default), `Prioritize Input 1`, `Always Add Input Number to Field Names` (e.g., `name_1`, `name_2`).
    *   `Merging Nested Fields`: `Deep Merge` (Default - merges nested objects recursively) or `Shallow Merge` (merges only top-level properties).
*   **Fuzzy Compare:** (Boolean) If enabled, treats values of different types as potentially equal during matching (e.g., `3` matches `"3"`). Disabled by default.
*   **Disable Dot Notation:** (Boolean) If enabled, prevents field names like `customer.id` from being interpreted as nested objects during matching or output.
*   **Multiple Matches:** (Combine by Matching Fields only) How to handle cases where one item in an input matches multiple items in another input.
    *   `Include All Matches` (Default): Creates separate output items for each match.
    *   `Include First Match Only`: Outputs only the first match found.
*   **Include Any Unpaired Items:** (Combine by Position only) (Boolean) If enabled, items from the longer input stream that don't have a positional match in the shorter stream are still included in the output. Disabled by default.

## Use Cases

*   Rejoining data streams after an If node.
*   Combining results from parallel processing branches.
*   Enriching data from one source with related data from another (e.g., adding user details to order information).
*   Appending results from multiple queries or API calls.
*   Selecting a specific data path based on workflow logic while ensuring all paths complete.
*   Performing complex joins using SQL queries directly within the workflow.

## Considerations

*   **Execution Wait:** The Merge node always waits for *all* connected inputs to finish and provide data before it executes.
*   **Uneven Item Counts (Position Mode):** When merging by position, if inputs have different numbers of items, the behavior depends on the `Include Any Unpaired Items` option.
*   **Performance (All Combinations):** The `All Possible Combinations` mode can generate a very large number of output items (Input1_Count * Input2_Count * ...) and should be used cautiously.

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.merge/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.merge/)*

---

## 2.11. moveBinaryData

# Move Binary Data Node

Use the Move Binary Data node (`n8n-nodes-base.movebinarydata`) to convert data between JSON format and binary format within your n8n workflow items. This is crucial for handling file data or preparing data for nodes that expect specific formats.

## Modes

*   **JSON to Binary**: Converts data from a specified JSON property into a binary property.
*   **Binary to JSON**: Converts data from a specified binary property into a JSON property.

## Parameters

### JSON to Binary Mode

*   **Source Key**: The name of the JSON property containing the data to convert (e.g., `myData`, `fileContent`).
*   **Destination Key**: The name for the new binary property that will hold the converted data (e.g., `data`, `binaryFile`).
*   **File Name**: (Optional) Specify a file name to associate with the binary data. This is useful when the binary data represents a file.
*   **MIME Type**: (Optional) Specify the MIME type of the data (e.g., `application/json`, `text/plain`, `image/png`).

### Binary to JSON Mode

*   **Source Key**: The name of the binary property containing the data to convert (e.g., `data`, `downloadedFile`).
*   **Destination Key**: The name for the new JSON property that will hold the converted data (e.g., `jsonData`, `extractedText`).
*   **Options**:
    *   **Assume String Data**: (Toggle) If enabled, n8n attempts to decode the binary data as a UTF-8 string. If disabled, the raw buffer might be represented differently in JSON.

## Use Cases

*   **Preparing Data for Upload**: Convert JSON data into a binary property before sending it to an HTTP Request node or a service-specific node that uploads files.
*   **Processing Downloaded Files**: Convert binary data (e.g., downloaded via HTTP Request) into JSON format (often as a string) for parsing or further manipulation.
*   **Handling Base64 Data**: Convert Base64 encoded strings (in JSON) to binary, or vice-versa.
*   **Changing Data Representation**: Explicitly manage how data is represented (JSON vs. binary) between different nodes in a workflow.

*Note: This node primarily changes the representation of data within an n8n item. It does not inherently perform file type conversions (e.g., JSON to PDF). It moves data between the `json` and `binary` objects of an item.*

*Sources: Synthesized from community discussions and n8n.io integration page (e.g., [https://community.n8n.io/t/how-to-read-binary-data/4007](https://community.n8n.io/t/how-to-read-binary-data/4007), [https://n8n.io/integrations/move-binary-data/](https://n8n.io/integrations/move-binary-data/))*

---

## 2.12. renameKeys

# n8n Core Node: Rename Keys

## Overview

The Rename Keys node (`n8n-nodes-base.renamekeys`) is a core utility node designed specifically to rename the keys (field names) within the JSON data of n8n items. It provides a straightforward way to modify the structure of your data by changing how fields are named.

## Functionality

This node iterates through the JSON data of each incoming item and renames specified keys according to the rules defined in its parameters. It can rename keys individually or use regular expressions for pattern-based renaming.

## Parameters

### Manual Key Renaming

*   **Add new key:** Button to add a mapping for renaming a single key.
*   **Fields (per mapping):**
    *   `Current Key Name`: The exact name of the key you want to rename.
    *   `New Key Name`: The desired new name for the key.

### Regex Renaming (Optional)

*   **Use Regex:** (Boolean) Enable this toggle to use regular expressions for renaming.
*   **Regular Expression:** The JavaScript-style regular expression pattern to match against existing key names. Capturing groups can be used.
*   **Replace With:** The replacement string for matched keys. Can use captured groups from the regex (e.g., `$1`, `$2`).
*   **Regex Options:**
    *   `Case Insensitive`: (Boolean) If enabled, the regex matching ignores case.
    *   `Max Depth`: (Integer) Controls how deep into nested objects the regex renaming should apply. `-1` means unlimited depth (default), `0` means only top-level keys.

## Considerations

*   **Order of Operations:** If both manual renaming and regex renaming are used, the manual renames are typically applied first. Be aware that a regex might subsequently rename a key that was already manually renamed if it matches the pattern.
*   **Nested Keys:** Renaming nested keys directly (e.g., renaming `customer.address.street` to `customer.address.road`) might require careful handling or using regex with appropriate depth, depending on the node's implementation details. Often, it's simpler to rename top-level keys or use a Set/Code node for complex restructuring.
*   **Regex Impact:** Using a broad regular expression can unintentionally rename many keys. Test carefully.

## Use Cases

*   **Standardizing Field Names:** Renaming keys from different API sources to a consistent internal format (e.g., changing `user_id`, `UserID`, `userId` all to `userID`).
*   **Simplifying Key Names:** Shortening long or complex key names received from external systems.
*   **Preparing Data for Other Nodes:** Renaming keys to match the expected input format of a subsequent node (e.g., renaming fields to match database column names before an Insert operation).
*   **Removing Prefixes/Suffixes:** Using regex to strip common prefixes or suffixes from multiple keys.

## Example Scenario: Standardizing User ID

Input item JSON: `{"user_id": 123, "name": "Alice"}`

**Rename Keys Node Configuration:**

*   Manual Mapping:
    *   Current Key Name: `user_id`
    *   New Key Name: `userID`

Output item JSON: `{"userID": 123, "name": "Alice"}`

## Example Scenario: Using Regex

Input item JSON: `{"prop_color": "red", "prop_size": "large", "name": "widget"}`

**Rename Keys Node Configuration:**

*   Use Regex: Enabled
*   Regular Expression: `^prop_(.*)`
*   Replace With: `$1`

Output item JSON: `{"color": "red", "size": "large", "name": "widget"}`

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.renamekeys/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.renamekeys/)*

---

## 2.13. set

# n8n Core Node: Edit Fields (Set)

## Overview

The Edit Fields node (internally `n8n-nodes-base.set`, often referred to as "Set" in older contexts or internally) is a fundamental core node used to add, modify, or overwrite data fields within n8n items. It is essential for preparing data for subsequent nodes, mapping values, creating new data structures, and controlling the data flow.

## Functionality

This node allows you to define new fields or target existing fields within each incoming item and set their values. Values can be static (fixed strings, numbers, booleans) or dynamic (using n8n expressions to reference data from the input item or other workflow context).

## Modes of Operation

The node offers two primary modes for defining how fields are set:

*   **Manual Mapping (GUI):** This mode provides a user-friendly interface where you can add rows for each field you want to set. 
    *   **Name:** Define the name of the field to be created or overwritten. By default, n8n supports dot notation, meaning a name like `customer.address.city` will create a nested structure. This can be disabled in the node options.
    *   **Value:** Define the value for the field. You can toggle between:
        *   **Expressions (Default):** Enter an n8n expression (e.g., `{{ $json.firstName }}`) to dynamically pull data from the input or context.
        *   **Fixed:** Enter a static value (string, number, boolean).
*   **JSON Output:** This mode allows you to define a JSON object directly. The keys and values in this JSON object will be merged with the incoming item's data. You can use n8n expressions within the JSON values (e.g., `"userId": "{{ $json.id }}"`).

## Parameters

### Mode
*   Select `Manual Mapping` or `JSON Output`.

### Fields to Set (Manual Mapping Mode)
*   A list where you add rows for each field.
    *   **Name:** The target field name (supports dot notation by default).
    *   **Value:** The value to set (can be Fixed or an Expression).

### JSON Output (JSON Output Mode)
*   A text area to input the JSON object that will be merged into the item.

### Keep Only Set Fields
*   **Description:** (Boolean) If enabled, only the fields explicitly defined in the 'Fields to Set' (Manual Mapping) or the JSON Output will be kept in the output item. All other fields from the input item will be discarded.
*   **Default:** Disabled.

### Include in Output
*   **Description:** Controls which data from the *input* item is included in the *output* item, alongside the newly set fields.
*   **Options:**
    *   `All Input Fields` (Default): All original fields are passed through.
    *   `Selected Input Fields`: Allows specifying which input fields to keep.
    *   `No Input Fields`: Only the newly set fields (and potentially binary data, see options) are output.

## Node Options

*   **Include Binary Data:** (Boolean) If the input item contains binary data (e.g., from reading a file), enabling this option ensures the binary data is passed through to the output item, even if `Keep Only Set Fields` is enabled or `Include in Output` is set to `No Input Fields`.
*   **Ignore Type Conversion Errors:** (Boolean, Manual Mapping only) If enabled, n8n attempts to ignore certain data type mismatches during mapping, potentially allowing the workflow to continue where it might otherwise error.
*   **Support Dot Notation:** (Boolean) Controls whether field names entered in Manual Mapping mode are interpreted using dot notation to create nested objects. Enabled by default.

## Use Cases

*   Adding new fields with static or dynamic values to items.
*   Renaming fields by setting a new field with the value of an old field (often combined with `Keep Only Set Fields`).
*   Restructuring data before sending it to an API or database.
*   Creating default values for fields that might be missing.
*   Simplifying complex objects by selecting and keeping only necessary fields.
*   Converting data types implicitly (e.g., setting a number field with a string value containing a number).
*   Preparing data structures required by subsequent nodes (e.g., formatting data for a spreadsheet row).

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.set/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.set/)*

---

## 2.14. xml

# XML Node

Use the XML node (`n8n-nodes-base.xml`) to convert data between JSON and XML formats within your n8n workflows.

**Note:** If your XML data is contained within a binary file, you must first use the `Extract from File` node to convert the file content into text before using the XML node.

## Node Parameters

*   **Mode**: Select the conversion direction:
    *   `JSON to XML`: Converts JSON data into an XML structure.
    *   `XML to JSON`: Converts XML data into a JSON structure.
*   **Property Name**: Specify the name of the field in the incoming n8n item that holds the data (either JSON or XML string) to be converted.

## Node Options (General)

These options apply regardless of the selected **Mode**:

*   **Attribute Key**: Defines the prefix used in the JSON structure to denote XML attributes. Default: `$`.
*   **Character Key**: Defines the prefix used in the JSON structure to denote the character content (text value) of an XML element. Default: `_`.

## Node Options (JSON to XML Mode)

These options are available only when **Mode** is set to `JSON to XML`:

*   **Allow Surrogate Chars**: (Toggle) If enabled, allows characters from Unicode surrogate blocks in the output XML.
*   **Cdata**: (Toggle) If enabled, wraps text content requiring XML escaping within `<![CDATA[ ... ]]>` sections instead of using standard XML entity escaping.
*   **Headless**: (Toggle) If enabled, omits the standard XML declaration header (e.g., `<?xml version="1.0" encoding="UTF-8"?>`) from the output.
*   **Root Name**: Specify the desired name for the root element of the generated XML document.

## Node Options (XML to JSON Mode)

These options are available only when **Mode** is set to `XML to JSON`:

*   **Explicit Array**: (Toggle) If enabled, ensures that all child elements are placed within arrays in the resulting JSON, even if there is only one child. If disabled (default), arrays are only created when an element has multiple children with the same name.
*   **Explicit Root**: (Toggle) If enabled, includes the XML root element as the top-level object in the resulting JSON. If disabled (default), the content of the root element becomes the top-level JSON structure.
*   **Ignore Attributes**: (Toggle) If enabled, all XML attributes are discarded during conversion, and only element text content is preserved.
*   **Merge Attributes**: (Toggle) If enabled, XML attributes are merged directly as properties into the parent JSON object alongside child elements. If disabled (default), attributes are placed within a separate child object keyed by the **Attribute Key** (e.g., `$`). This option is ignored if **Ignore Attributes** is enabled.
*   **Normalize**: (Toggle) If enabled, trims whitespace from within text nodes.
*   **Normalize Tags**: (Toggle) If enabled, converts all XML tag names to lowercase in the resulting JSON keys.
*   **Trim**: (Toggle) If enabled, removes leading and trailing whitespace from text node content.

## Use Cases

*   Parsing XML responses from APIs or web services.
*   Generating XML payloads for SOAP requests or other XML-based APIs.
*   Converting between JSON and XML data formats for system integration.

*Source: Based on the official documentation page [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.xml/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.xml/)*

---

## 3.1. compareDatasets

# n8n Core Node: Compare Datasets

## Overview

The Compare Datasets node (`n8n-nodes-base.comparedatasets`) is a core utility node designed to compare items between two distinct input streams (Input A and Input B). It identifies matching items based on specified key fields and categorizes them based on whether they are identical, different, or unique to one input.

## Functionality

The node takes two inputs, typically representing two lists of items (e.g., data from two different databases, spreadsheets, or API responses). It performs the comparison in two stages:

1.  **Matching:** It first tries to find pairs of items, one from Input A and one from Input B, where the values in the specified key fields (`Input A Field`, `Input B Field`) are identical. You can specify multiple key fields for matching.
2.  **Comparing:** Once a match based on the key fields is found, the node compares *all other* fields (unless skipped) within the matched pair to determine if the items are identical or different.

## Node Parameters

*   **Input A Field:** The field name in items from Input A to use as a key for matching.
*   **Input B Field:** The field name in items from Input B to use as a key for matching.
*   **Add Fields to Match:** Allows specifying additional pairs of key fields for matching. All specified key fields must match for items to be considered a pair.
*   **When There Are Differences:** Determines how to structure the output for items that match on key fields but differ in other fields.
    *   `Use Input A Version`: Output the version from Input A.
    *   `Use Input B Version`: Output the version from Input B.
    *   `Use a Mix of Versions`: Choose a primary source (`Prefer`) and specify fields (`For Everything Except`) to take from the *other* source.
    *   `Include Both Versions`: Output includes data from both Input A and Input B, potentially creating a more complex structure.
*   **Fuzzy Compare:** (Boolean) If enabled, allows for tolerance in type differences during comparison (e.g., number `3` matches string `"3"`).

## Node Options

*   **Fields to Skip Comparing:** A comma-separated list of field names to ignore during the second stage (comparing all fields) after a key match is found. Useful for ignoring fields like timestamps or IDs that are expected to differ.
*   **Disable Dot Notation:** (Boolean) If enabled, prevents using dot notation (e.g., `parent.child`) when specifying field names. Default is off (dot notation allowed).
*   **Multiple Matches:** Defines behavior when a key matches multiple items in the other input.
    *   `Include All Matches` (Default): If an item in Input A matches multiple items in Input B (or vice-versa), all matches are considered.
    *   `Include First Match Only`: Only the first match found is considered.

## Outputs

The Compare Datasets node has four distinct outputs:

1.  **Input A Only:** Items from Input A that had no matching key in Input B.
2.  **Input B Only:** Items from Input B that had no matching key in Input A.
3.  **Identical:** Pairs of items (one from A, one from B) that matched on the key field(s) AND were identical in all other compared fields.
4.  **Different:** Pairs of items (one from A, one from B) that matched on the key field(s) BUT differed in at least one other compared field. The structure of items in this output depends on the `When There Are Differences` parameter setting.

## Use Cases

*   **Data Synchronization:** Identifying records that need to be added, updated, or deleted between two systems (e.g., comparing a database table with a spreadsheet).
*   **Change Detection:** Finding differences between two versions of a dataset.
*   **Reconciliation:** Comparing lists of transactions, users, or products from different sources.
*   **Finding Unique/Missing Items:** Isolating items present in one dataset but not the other.

## Example Scenario: Comparing User Lists

1.  **Input A:** Contains a list of users from Database 1.
2.  **Input B:** Contains a list of users from CRM.
3.  **Compare Datasets Node:**
    *   Input A Field: `email`
    *   Input B Field: `email`
    *   When There Are Differences: `Use Input B Version` (prefer CRM data)
4.  **Outputs:**
    *   `Input A Only`: Users only in Database 1.
    *   `Input B Only`: Users only in CRM (potential new users).
    *   `Identical`: Users present in both with matching details.
    *   `Different`: Users present in both but with differing details (e.g., phone number). The output items will have the data structure from Input B (CRM).

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.comparedatasets/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.comparedatasets/)*

---

## 3.2. filter

# n8n Core Node: Filter

## Overview

The Filter node (`n8n-nodes-base.filter`) is a core flow control node used to selectively pass items to the next node based on whether they meet specified conditions. Items that meet the conditions proceed through the node's output, while items that do not meet the conditions are discarded for that branch.

## Functionality

The node evaluates each incoming item against one or more defined conditions. Conditions compare the value of a field within the item's JSON data against a specified value or pattern using various comparison operators.

## Node Parameters

*   **Conditions:** Define the rules for filtering.
    *   **Add Condition:** Button to add a new comparison rule.
    *   **Per Condition:**
        *   **Data Type:** Select the type of data to compare (String, Number, Date & Time, Boolean, Array, Object).
        *   **Comparison Operator:** Choose the comparison method based on the selected data type (e.g., `is equal to`, `contains`, `is after`, `exists`, `matches regex`).
        *   **Value Fields:** Input fields appear based on the chosen operator, allowing you to specify the field from the incoming item (`Value 1`) and the value to compare against (`Value 2`). Expressions can be used in these fields.
*   **Combining Conditions:** If multiple conditions are added:
    *   **AND:** Items must meet *all* defined conditions to pass.
    *   **OR:** Items must meet *at least one* of the defined conditions to pass.
    *   *(Note: Mixing AND and OR logic within a single Filter node is not supported. Use multiple Filter nodes or an If node for more complex logic.)*

## Node Options

*   **Ignore Case:** (Boolean) If enabled, string comparisons ignore letter case.
*   **Less Strict Type Validation:** (Boolean) If enabled, n8n attempts type coercion during comparison (e.g., treating number `123` and string `"123"` as equal if the operator allows). Useful for handling inconsistent data types, but use with caution.

## Comparison Operators by Data Type

*   **String:** exists, does not exist, is empty, is not empty, is equal to, is not equal to, contains, does not contain, starts with, does not start with, ends with, does not end with, matches regex, does not match regex.
*   **Number:** exists, does not exist, is empty, is not empty, is equal to, is not equal to, is greater than, is less than, is greater than or equal to, is less than or equal to.
*   **Date & Time:** exists, does not exist, is empty, is not empty, is equal to, is not equal to, is after, is before, is after or equal to, is before or equal to.
*   **Boolean:** exists, does not exist, is empty, is not empty, is true, is false, is equal to, is not equal to.
*   **Array:** exists, does not exist, is empty, is not empty, contains, does not contain, length equal to, length not equal to, length greater than, length less than, length greater than or equal to, length less than or equal to.
*   **Object:** exists, does not exist, is empty, is not empty.

## Use Cases

*   Processing only items that meet certain criteria (e.g., orders with status 'completed', users from a specific country).
*   Removing items with missing or invalid data before further processing.
*   Routing items based on simple conditions before more complex logic is applied by other nodes.
*   Selecting items based on date ranges, numerical thresholds, or text patterns.

## Difference from If Node

*   **Filter Node:** Has only one output. Items either pass through if they meet the condition(s) or are stopped.
*   **If Node:** Has two outputs (true/false). All items are routed to one of the two outputs based on whether they meet the condition(s).

Choose the Filter node when you only want to proceed with items meeting the criteria and discard the rest for that specific path. Choose the If node when you need to route all items down different paths based on the condition.

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.filter/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.filter/)*

---

## 3.3. if

# n8n Core Node: If

## Overview

The If node (`n8n-nodes-base.if`) is a fundamental core node used for conditional branching within an n8n workflow. It evaluates incoming items against one or more defined conditions and routes each item to either its `true` or `false` output path based on the outcome of the evaluation.

## Functionality

The If node allows you to create decision points in your workflow. It examines each item passed to it and directs the item down one of two paths:

1.  **True Path:** If the item satisfies the defined condition(s).
2.  **False Path:** If the item does not satisfy the defined condition(s).

This enables different actions to be taken based on the data within each item.

## Node Parameters

*   **Conditions:** Define the rules for routing items.
    *   **Add Condition:** Button to add a new comparison rule.
    *   **Per Condition:**
        *   **Data Type:** Select the type of data to compare (String, Number, Date & Time, Boolean, Array, Object).
        *   **Comparison Operator:** Choose the comparison method based on the selected data type (e.g., `is equal to`, `contains`, `is greater than`, `is after`, `is true`, `length equal to`). See the full list below.
        *   **Value Fields:** Input fields appear based on the chosen operator, allowing you to specify the field from the incoming item (`Value 1`) and the value to compare against (`Value 2`). Expressions (e.g., `={{ $json.status }}`, `={{ $now }}`) are commonly used here.
*   **Combining Conditions:** If multiple conditions are added:
    *   **AND:** Items must meet *all* defined conditions to be routed to the `true` output.
    *   **OR:** Items must meet *at least one* of the defined conditions to be routed to the `true` output.
    *   *(Note: Mixing AND and OR logic within a single If node is not supported. Use multiple If nodes or potentially a Code node for more complex nested logic.)*

## Node Options

*   **Ignore Case:** (Boolean) If enabled, string comparisons ignore letter case.
*   **Less Strict Type Validation:** (Boolean) If enabled, n8n attempts type coercion during comparison (e.g., treating number `123` and string `"123"` as equal if the operator allows). Useful for handling inconsistent data types, but use with caution.

## Comparison Operators by Data Type

*   **String:** exists, does not exist, is empty, is not empty, is equal to, is not equal to, contains, does not contain, starts with, does not start with, ends with, does not end with, matches regex, does not match regex.
*   **Number:** exists, does not exist, is empty, is not empty, is equal to, is not equal to, is greater than, is less than, is greater than or equal to, is less than or equal to.
*   **Date & Time:** exists, does not exist, is empty, is not empty, is equal to, is not equal to, is after, is before, is after or equal to, is before or equal to.
*   **Boolean:** exists, does not exist, is empty, is not empty, is true, is false, is equal to, is not equal to.
*   **Array:** exists, does not exist, is empty, is not empty, contains, does not contain, length equal to, length not equal to, length greater than, length less than, length greater than or equal to, length less than or equal to.
*   **Object:** exists, does not exist, is empty, is not empty.

## Use Cases

*   Routing orders based on their status (e.g., send confirmation for 'paid', send reminder for 'pending').
*   Handling different types of user requests based on input data.
*   Checking if required data fields exist before proceeding.
*   Performing different actions based on whether an API call was successful or returned specific data.
*   Creating simple A/B splits in a workflow.

## Difference from Filter and Switch Nodes

*   **If Node:** Has exactly two outputs (`true`, `false`). All items go down one of these two paths.
*   **Filter Node:** Has only one output. Items meeting the condition pass; others are discarded for that path.
*   **Switch Node:** Has multiple outputs based on matching a single input value against several defined cases. Provides more than two branches based on specific values, not complex conditions.

## Legacy Execution Behavior (Versions < 1.0)

In n8n versions prior to 1.0 (using the v0 execution order), combining an If node with a Merge node could lead to unexpected execution of both the true and false branches, as the Merge node would wait for and potentially trigger the inactive branch. This behavior was changed in v1.0+.

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.if/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.if/)*

---

## 3.4. limit

# Limit Node

Use the Limit node (`n8n-nodes-base.limit`) to restrict the number of items passing through a workflow. It removes items that exceed a specified maximum count.

## Node Parameters

*   **Max Items**: Enter the maximum number of items to keep. Any items beyond this count will be removed.
*   **Keep**: Select which items to keep if the input contains more than **Max Items**:
    *   **First Items**: Keeps the specified number of items from the beginning of the input list.
    *   **Last Items**: Keeps the specified number of items from the end of the input list.

## Use Cases

*   Processing only the first N results from an API call.
*   Handling only the most recent N items from a trigger.
*   Reducing the number of items before a resource-intensive operation.

*Source: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.limit/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.limit/)*
*Related: [Data structure and data flow](https://docs.n8n.io/data/)*

---

## 3.5. removeDuplicates

# Remove Duplicates Node

Use the Remove Duplicates node (`n8n-nodes-base.removeduplicates`) to identify and filter out duplicate items within a workflow execution or across multiple executions.

## Operation Modes

The node offers three main modes of operation:

1.  **Remove Items Repeated Within Current Input**: Identifies and removes duplicate items based on the data received in the current execution only.
    *   **Compare**: Choose which fields to compare for identifying duplicates:
        *   **All Fields**: Compares the entire JSON object of each item.
        *   **All Fields Except**: Compares all fields *except* those specified.
        *   **Selected Fields**: Compares only the specified fields.
    *   **Options** (for 'All Fields Except' or 'Selected Fields'):
        *   **Disable Dot Notation**: Toggle whether to use dot notation (e.g., `parent.child`) for field selection.
        *   **Remove Other Fields**: Choose whether to keep only the compared fields in the output or keep all original fields.

2.  **Remove Items Processed in Previous Executions**: Compares incoming items against a history of items processed in previous workflow executions and removes items based on specified criteria.
    *   **Keep Items Where**: Define the condition for keeping an item:
        *   **Value Is New**: Keeps items whose specified value(s) haven't been seen in previous runs.
        *   **Value Is Higher than Any Previous Value**: Keeps items only if their specified numeric value is greater than any corresponding value seen previously.
        *   **Value Is a Date Later than Any Previous Date**: Keeps items only if their specified date value is later than any corresponding date seen previously.
    *   **Value to Dedupe On**: Specify the field(s) containing the value(s) to compare against the history. The required format depends on the 'Keep Items Where' selection (unique ID, incremental number, or ISO date).
    *   **Options**:
        *   **Scope**: Determine where the history is stored:
            *   **Node**: History is specific to this node instance.
            *   **Workflow**: History is shared among all Remove Duplicates nodes in the workflow set to 'Workflow' scope.
        *   **History Size** (only for 'Value Is New'): Set the maximum number of unique values to remember from previous executions (default: 10,000). Operates like a FIFO queue when the limit is reached.

3.  **Clear Deduplication History**: Manages the stored history used by the 'Remove Items Processed in Previous Executions' mode.
    *   **Mode**: Currently only supports **Clean Database**, which deletes all stored history items.
    *   **Options**:
        *   **Scope**: Choose whether to clear the history for this specific **Node** or for the entire **Workflow** (affecting all nodes using 'Workflow' scope).

## Use Cases

*   **Data Cleaning**: Removing duplicate entries from API responses or database queries within a single run.
*   **Processing Only New Items**: Ensuring that only new records (e.g., new orders, new users) are processed by comparing against previous runs.
*   **Handling Incremental Updates**: Processing items only if they represent a higher value or later date than previously seen items (e.g., updated sensor readings, latest status changes).

*Source: Based on the official documentation page [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.removeduplicates/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.removeduplicates/)*

---

## 3.6. sort

# Sort Node

Use the Sort node (`n8n-nodes-base.sort`) to organize a list of incoming n8n items based on specified criteria or to randomize their order.

## Node Parameters

The primary parameter is **Type**, which determines the sorting method:

*   **Simple**: Sorts items based on the value of one or more fields in ascending or descending order.
    *   **Add Field To Sort By**: Click this to specify a field.
        *   **Field Name**: The name of the field within the item to use for sorting. Supports dot notation by default (e.g., `customer.name`).
        *   **Order**: Choose `Ascending` or `Descending`.
    *   **Options**:
        *   **Disable Dot Notation**: (Toggle) Turn this on to treat field names literally (e.g., `customer.name` as a single field name) instead of interpreting dots as nested object access.
*   **Random**: Randomly shuffles the order of the incoming items.
*   **Code**: Allows you to define a custom sorting logic using JavaScript. This provides maximum flexibility for complex sorting requirements.
    *   **Code**: Enter your JavaScript comparison function here. The function receives two items (`a` and `b`) as arguments and should return:
        *   A negative value if `a` should come before `b`.
        *   A positive value if `a` should come after `b`.
        *   Zero if their order doesn't matter relative to each other.

**Important Note on Array Sort Behavior:** The Simple sort operation relies on the default JavaScript `Array.prototype.sort()` behavior. This means values are often converted to strings before comparison. For purely numerical sorting, ensure your data types are numbers or use the Code mode for explicit numerical comparison.

## Use Cases

*   Ordering items alphabetically based on a name or title field before further processing.
*   Sorting items numerically based on a score, price, or ID.
*   Arranging items chronologically based on a date field.
*   Randomizing a list of items for selection or display.
*   Implementing complex, multi-field sorting logic using custom code.

*Source: Based on the official documentation page [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.sort/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.sort/)*

---

## 3.7. splitInBatches

# n8n Core Node: Loop Over Items (Split in Batches)

## Overview

The Loop Over Items node (`n8n-nodes-base.splitinbatches`), often referred to as "Split in Batches", is a core flow control node designed to process a list of incoming items iteratively in smaller, manageable batches. It provides explicit looping capabilities when the default item-by-item processing of n8n nodes is insufficient or needs modification.

## Functionality

1.  **Batching:** The node takes all incoming items and divides them into batches based on the specified `Batch Size`.
2.  **Iteration:** For each batch, it outputs the items through its **loop** output. Nodes connected to this output process the current batch.
3.  **Looping:** The crucial part is connecting the last node in the loop path *back* to the input of the Loop Over Items node. This signals the node to output the next batch.
4.  **Completion:** Once all batches have been processed and looped back, the node outputs the *combined results* from all loop iterations through its **done** output.
5.  **Context Preservation:** The node internally keeps track of the original input items and the current batch index.

## When to Use

While n8n nodes typically process all incoming items automatically, the Loop Over Items node is necessary in specific scenarios:

*   **Rate Limiting:** When calling APIs that have rate limits, you can use this node with a `Wait` node in the loop to process items in small batches with delays, preventing errors.
*   **Nodes Processing Only the First Item:** Some nodes (like older versions of certain triggers or specific API nodes) might only process the first item they receive. Looping with a batch size of 1 ensures each item is processed individually by such nodes.
*   **Sequential Dependencies:** When the processing of one item depends on the result of the previous one within the same original list.
*   **Complex Aggregation/State Management:** When you need to maintain a state or aggregate results across batches in a specific way that standard nodes don't support.
*   **Unknown Iteration Count (with Reset):** When looping based on a condition (e.g., fetching paginated data until no more pages are left), using the `Reset` option allows the loop to continue based on dynamic conditions evaluated within the loop path.

## Node Parameters

*   **Batch Size:** (Required) The number of items to include in each batch sent through the **loop** output. Setting it to `1` processes items individually.

## Node Options

*   **Reset:** (Boolean)
    *   **Off (Default):** The node processes the initial incoming data in batches until all items are exhausted.
    *   **On:** The node expects data to be fed back into it continuously. With each loop-back, it treats the *newly received* data as the set to be processed, effectively resetting its internal state based on the latest input. This is crucial for conditional looping (e.g., pagination) where the loop continues based on results from the previous iteration. Requires careful implementation of an exit condition (often using an `If` node) to prevent infinite loops.
    *   **Reset Condition (Expression):** When `Reset` is on, you can define an expression. The loop resets only if this expression evaluates to true.

## Outputs

*   **loop:** Outputs the current batch of items for processing within the loop path.
*   **done:** Outputs the combined results from *all* iterations *after* the loop has finished processing all original items (or the exit condition is met when using `Reset`).

## Context Variables (Useful in Expressions)

*   `{{ $node["Loop Over Items"].context["currentRunIndex"] }}`: Returns the 0-based index of the current loop iteration.
*   `{{ $node["Loop Over Items"].context["noItemsLeft"] }}`: Returns `true` if all items have been processed and sent through the loop output, `false` otherwise. Useful for exit conditions in loops.

## Important Considerations

*   **Connecting the Loop:** You *must* connect the end of your loop processing path back to the input of the Loop Over Items node for it to iterate through subsequent batches.
*   **Done Output:** Processing continues from the **done** output only *after* all batches are finished.
*   **Reset and Infinite Loops:** When using the `Reset` option, ensure a reliable exit condition (e.g., using an `If` node checking `noItemsLeft` or a specific data condition) is implemented in the loop path to prevent infinite executions.

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.splitinbatches/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.splitinbatches/)*

---

## 3.8. stopAndError

# n8n Core Node: Stop And Error

## Overview

The Stop And Error node (`n8n-nodes-base.stopanderror`) is a core flow control node used to intentionally halt a workflow's execution and mark it as failed. It allows you to define custom error conditions and messages, providing more control over error handling and reporting than default node failures.

## Functionality

When an item reaches the Stop And Error node, the node immediately stops the current workflow execution and flags it as failed. This is useful for:

*   **Validation:** Checking if data meets certain criteria before proceeding (e.g., ensuring required fields are present or have valid values). If validation fails, the workflow can be stopped with a clear error message.
*   **Custom Error Reporting:** Triggering a failure with a specific message or error object that can be caught by n8n's error handling mechanisms (like Error Workflows).
*   **Preventing Undesired Actions:** Stopping the workflow before potentially problematic actions occur based on preceding logic.

## Operations

The node has two modes of operation, selected via the `Error Type` parameter:

1.  **Error Message:**
    *   **Functionality:** Stops the workflow and reports a simple, custom text message as the error.
    *   **Parameter:** `Error Message` (Text field): Enter the specific error message to be displayed and logged.

2.  **Error Object:**
    *   **Functionality:** Stops the workflow and reports a custom JSON object as the error. This allows for more structured error information to be passed, which can be particularly useful for error workflows that parse error details.
    *   **Parameter:** `Error Object` (JSON field): Enter a valid JSON object containing the error details (e.g., `{"code": "VALIDATION_FAILED", "details": "User email is missing"}`).

## Use Cases

*   Stopping a workflow if an API call returns an unexpected status code or payload.
*   Validating input data from a webhook or form trigger and failing the execution if data is missing or invalid.
*   Creating custom error conditions within complex logic (e.g., after an If or Switch node) to signal specific failure scenarios.
*   Sending detailed, structured error information to a dedicated Error Workflow for logging or notification purposes.

## Integration with Error Workflows

The Stop And Error node is often used in conjunction with n8n's [Error Workflow](https://docs.n8n.io/flow-logic/error-handling/#error-workflows) feature. When this node triggers a failure:

*   If an Error Workflow is configured for the main workflow, it will be triggered.
*   The Error Workflow receives data about the failed execution, including the custom message or object defined in the Stop And Error node.
*   This allows for centralized and customized handling of specific, anticipated failure points in your workflows.

## Example Scenario: Input Validation

1.  **Webhook Node:** Receives data.
2.  **If Node:** Checks if `{{ $json.body.email }}` exists and is not empty.
    *   **True Output:** (Email exists) -> Continue workflow.
    *   **False Output:** (Email missing) -> Connect to Stop And Error node.
3.  **Stop And Error Node:**
    *   Error Type: `Error Message`
    *   Error Message: `Input validation failed: Email address is required.`
4.  **(Workflow Execution):** If the webhook receives data without an email, the If node routes to Stop And Error, the workflow halts, and the specified error message is logged.

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.stopanderror/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.stopanderror/)*

---

## 3.9. switch

# n8n Core Node: Switch

## Overview

The Switch node (`n8n-nodes-base.switch`) is a core flow control node that routes incoming items to different output branches based on defined conditions or rules. It acts like a multi-way `If` node, allowing for more than two possible paths based on the input data.

## Functionality

The Switch node evaluates each incoming item against a set of rules or an expression. Based on the evaluation, it directs the item to one of its multiple output ports (numbered 0, 1, 2, etc.).

## Node Parameters

The primary parameter is **Mode**, which determines how routing is decided:

### Mode: Rules

This mode allows defining specific conditions for each output branch.

*   **Routing Rules:** A list where each rule corresponds to an output branch (Output 0, Output 1, etc.).
    *   **Add Routing Rule:** Adds a new rule and corresponding output branch.
    *   **Per Rule:**
        *   **Data Type:** Select the type of data to compare (String, Number, Date & Time, Boolean, Array, Object).
        *   **Comparison Operator:** Choose the comparison method based on the selected data type (e.g., `is equal to`, `contains`, `is greater than`, `is after`, `is true`, `length equal to`). See the full list below.
        *   **Value Fields:** Input fields appear based on the chosen operator, allowing you to specify the field from the incoming item (`Value 1`) and the value to compare against (`Value 2`). Expressions are commonly used.
*   **Rename Output:** (Boolean) If enabled, allows assigning a custom name to each output branch for clarity.
    *   **Output Name:** (Appears if Rename Output is enabled) Enter a descriptive name for the corresponding output.

#### Rule Options (Apply to Rules Mode)

*   **Fallback Output:** Determines where items go if they don't match *any* defined rule.
    *   `None` (Default): Items that don't match any rule are discarded.
    *   `Extra Output`: Adds a dedicated "Fallback" output branch for non-matching items.
    *   `Output 0`: Sends non-matching items to the first output branch (Output 0).
*   **Ignore Case:** (Boolean) If enabled, string comparisons ignore letter case.
*   **Less Strict Type Validation:** (Boolean) If enabled, n8n attempts type coercion during comparison.
*   **Send data to all matching outputs:** (Boolean)
    *   `Off` (Default): Sends the item only to the *first* output branch whose rule it matches.
    *   `On`: Sends the item to *every* output branch whose rule it matches.

### Mode: Expression

This mode uses a single JavaScript expression to determine the output branch for each item.

*   **Number of Outputs:** Define the total number of output branches the node should have.
*   **Output Index:** Write a JavaScript expression that evaluates to a number (0-based index) for each item. The item will be routed to the output branch corresponding to the returned index. If the expression returns an index outside the defined range or a non-numeric value, the item is typically discarded (unless specific error handling is implemented elsewhere).

## Use Cases

*   Routing items based on status (e.g., 'pending' -> Output 0, 'completed' -> Output 1, 'failed' -> Output 2).
*   Handling different types of events or requests based on a type field.
*   Implementing complex conditional logic with multiple distinct outcomes.
*   Distributing items to different processing paths based on calculated values (using Expression mode).

## Difference from If and Filter Nodes

*   **Switch Node:** Multiple outputs (defined by rules or number of outputs). Routes items to one or more specific branches based on matching rules or an expression.
*   **If Node:** Exactly two outputs (`true`, `false`). Routes items based on a single condition or set of combined conditions (AND/OR).
*   **Filter Node:** Only one output. Items meeting the condition pass; others are discarded for that path.

## Available Comparison Operators by Data Type (for Rules Mode)

*   **String:** exists, does not exist, is empty, is not empty, is equal to, is not equal to, contains, does not contain, starts with, does not start with, ends with, does not end with, matches regex, does not match regex.
*   **Number:** exists, does not exist, is empty, is not empty, is equal to, is not equal to, is greater than, is less than, is greater than or equal to, is less than or equal to.
*   **Date & Time:** exists, does not exist, is empty, is not empty, is equal to, is not equal to, is after, is before, is after or equal to, is before or equal to.
*   **Boolean:** exists, does not exist, is empty, is not empty, is true, is false, is equal to, is not equal to.
*   **Array:** exists, does not exist, is empty, is not empty, contains, does not contain, length equal to, length not equal to, length greater than, length less than, length greater than or equal to, length less than or equal to.
*   **Object:** exists, does not exist, is empty, is not empty.

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.switch/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.switch/)*

---

## 4.1. code

# n8n Core Node: Code

## Overview

The Code node (`n8n-nodes-base.code`) is a powerful core node that allows you to execute custom JavaScript or Python code directly within your n8n workflow. It replaced the legacy Function and Function Item nodes (from n8n version 0.198.0 onwards), offering a unified and enhanced interface for custom scripting.

## Functionality

This node provides a sandboxed environment to run arbitrary code snippets. It's essential for tasks involving complex data manipulation, custom logic implementation beyond the scope of standard nodes, conditional processing, and interacting with n8n's internal data structures and workflow context.

## Modes of Operation

The Code node can operate in two distinct modes, determining how it processes incoming items:

*   **Run Once for All Items (Default):** The code executes a single time. It receives all input items as an array (e.g., `$items` in JS, `_items` in Python) and is expected to return an array of output items.
*   **Run Once for Each Item:** The code executes separately for each individual input item it receives (e.g., `$input.item` or `$item` in JS, `_item` in Python). The code should return the modified item or potentially multiple items derived from the single input.

## Supported Languages

*   **JavaScript:** Runs within a Node.js environment. Supports modern JavaScript features, including Promises (`async`/`await`). Allows `console.log` for debugging. 
    *   **External Libraries:**
        *   **n8n Cloud:** Limited access; includes built-in Node.js modules like `crypto` and the `moment` npm package.
        *   **Self-Hosted:** Can be configured to allow importing external npm modules by enabling the feature via environment variables (e.g., `NODE_FUNCTION_ALLOW_EXTERNAL`).
*   **Python:** Executes Python code using [Pyodide](https://pyodide.org/en/stable/), which is CPython compiled to WebAssembly. 
    *   **Limitations:** Package availability is restricted to those included with Pyodide or pure Python wheels. Execution is generally slower than JavaScript due to the WebAssembly environment.

## Parameters

*   **Language:** Dropdown to select either `JavaScript` or `Python`.
*   **Mode:** Dropdown to select `Run Once for All Items` or `Run Once for Each Item`.
*   **JavaScript/Python Code:** The main text area where you write and edit your custom code.
*   **Ask AI (Cloud Only):** An input field where you can describe the desired functionality in natural language. n8n uses ChatGPT to generate corresponding JavaScript code (overwrites existing code).

## Built-in Methods and Variables

n8n injects helpful variables and utility methods into the code execution context:

*   **JavaScript (Accessed via `$` prefix):**
    *   `$items`: Array of all input items (in 'Run Once for All Items' mode).
    *   `$item` / `$input.item`: The current input item (in 'Run Once for Each Item' mode).
    *   `$workflow`: Information about the current workflow.
    *   `$execution`: Details about the current execution.
    *   `$env`: Access to environment variables defined in your n8n instance.
    *   `$json`, `$binary`: Access properties of an item.
    *   Utility methods like `$helpers.formatDate()`, `$helpers.sleep()`, etc.
*   **Python (Accessed via `_` prefix):**
    *   `_items`: List of all input items.
    *   `_item`: The current input item.
    *   `_workflow`, `_execution`, `_env`: Similar context information.
    *   Utility methods available through imported modules or potentially injected helpers.

*Full Reference:* [https://docs.n8n.io/code/builtin/overview/](https://docs.n8n.io/code/builtin/overview/)

## Key Concepts for Coding in n8n

*   **Data Structure:** n8n items are objects typically containing `json` (for structured data) and potentially `binary` (for file data) properties. Code usually manipulates the `json` property. Input is an array of items, and output should generally be an array of items.
*   **Item Linking:** Understand how n8n pairs input items with output items. If your code changes the number of items (e.g., filtering, splitting), you need to manage this relationship correctly, often by returning appropriate data structures.

## Limitations

*   **No Direct File System/HTTP:** The Code node cannot directly access the local file system or make arbitrary HTTP requests. Use dedicated nodes like `Read Binary File`, `Write Binary File`, or `HTTP Request` for these operations.
*   **Sandboxing:** Code runs in a restricted environment for security.
*   **Python Package Limits:** Python functionality is constrained by the packages available in Pyodide.

## Use Cases

*   Complex data transformations, calculations, or manipulations not covered by standard nodes.
*   Implementing custom business logic or algorithms.
*   Iterating through arrays or objects within an item's data.
*   Formatting data precisely for specific API requirements.
*   Conditional logic based on complex criteria.
*   Using specific functions from allowed external libraries (e.g., `moment` for date manipulation, `crypto` for hashing).

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.code/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.code/)*

---

## 5.1. executeCommand

# n8n Core Node: Execute Command

## Overview

The Execute Command node (`n8n-nodes-base.executecommand`) allows workflows to run shell commands directly on the host machine where the n8n instance is running. This provides a powerful way to interact with the underlying system, run scripts, or utilize command-line tools.

**Important Note:** This node is **not available on n8n Cloud** due to security restrictions. It only functions on self-hosted n8n instances.

## Functionality

The node executes the provided command within the default shell environment of the n8n host. If n8n is running in a Docker container, the command executes *inside the container*, not on the Docker host machine itself.

The node captures the standard output (stdout) and standard error (stderr) streams from the executed command and makes them available in its output data.

## Node Parameters

*   **Command:** The shell command to be executed. This field accepts expressions, allowing dynamic command generation based on input data.
    *   **Running Multiple Commands:** You can run multiple commands sequentially by:
        *   Separating them with `&&` on a single line (e.g., `cd /data && ls -l`).
        *   Placing each command on a new line within the Command field.
*   **Execute Once:** (Toggle)
    *   `Off` (Default): The command executes once for *each item* received by the node.
    *   `On`: The command executes only *once*, regardless of the number of input items. It typically uses data from the first item if expressions are involved.

## Output Data

The node outputs items containing:

*   `stdout`: The standard output generated by the command.
*   `stderr`: The standard error output generated by the command.
*   `exitCode`: The exit code returned by the command (0 typically indicates success).

## Use Cases

*   Running custom scripts (Python, Bash, Node.js, etc.) available on the host system.
*   Interacting with command-line interface (CLI) tools.
*   Performing file system operations (though dedicated file nodes are often safer).
*   Triggering system-level tasks.
*   Integrating with tools or processes not accessible via APIs.

## Important Considerations

*   **Security:** Executing arbitrary commands poses significant security risks. Only run trusted commands and carefully sanitize any user input used in constructing commands to prevent command injection vulnerabilities.
*   **Environment:** The command runs within the n8n process's environment (or container). Ensure any required tools, libraries, or environment variables are accessible within that context.
*   **Permissions:** The command runs with the permissions of the user running the n8n process. Ensure this user has the necessary permissions to execute the command and access required resources.
*   **Dependencies:** If the command relies on specific installed software (like `curl`, `git`, `python`), that software must be installed *within the n8n environment* (e.g., inside the Docker container). You might need to create a custom Docker image for n8n to include these dependencies.
*   **Long-Running Commands:** Be cautious with commands that might take a long time to complete, as they can block workflow execution.
*   **Error Handling:** Check the `exitCode` and `stderr` in the output to handle potential errors in the executed command.

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executecommand/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executecommand/)*

---

## 5.2. executeWorkflow

# n8n Core Node: Execute Sub-workflow

## Overview

The Execute Sub-workflow node (`n8n-nodes-base.executeworkflow`) allows a parent workflow to trigger and run another n8n workflow (the sub-workflow) located on the same n8n instance. It facilitates modular workflow design, enabling the reuse of common logic or breaking down complex processes into smaller, manageable parts.

## Functionality

This node acts as a caller. It locates the specified sub-workflow (via ID, file path, URL, or embedded JSON), sends input data to it, triggers its execution, and optionally waits to receive the output data from the sub-workflow's final node.

The sub-workflow must start with an **Execute Sub-workflow Trigger** node (also displayed as "When Executed by Another Workflow" in the trigger node list) to receive data from the calling parent workflow.

## Node Parameters

*   **Source:** Determines how the sub-workflow is identified:
    *   `Database`: Loads the workflow from the n8n instance's database.
        *   `From list`: Select the sub-workflow from a dropdown list of available workflows.
        *   `Workflow ID`: Manually enter the sub-workflow's ID (found in its URL).
    *   `Local File`: Loads the workflow from a JSON file on the n8n host's filesystem.
        *   **Workflow Path:** The absolute path to the `.json` file.
    *   `Parameter`: Loads the workflow definition directly from JSON embedded in the node.
        *   **Workflow JSON:** Paste the sub-workflow's JSON definition here.
    *   `URL`: Loads the workflow definition from a specified URL that returns the workflow JSON.
        *   **Workflow URL:** The URL to fetch the workflow JSON from.
*   **Workflow Inputs:** (Appears when `Source` is `Database` and `From list` is used, and the sub-workflow trigger defines inputs) Allows mapping data from the parent workflow to the expected input fields defined in the sub-workflow's trigger node.
    *   **Attempt to convert types:** (Boolean) Tries to automatically convert data types to match the sub-workflow's expected input types.
*   **Mode:** Controls how the sub-workflow is executed relative to the input items:
    *   `Run once with all items`: The sub-workflow runs a single time, receiving all input items from the parent node as a list.
    *   `Run once for each item` (Default): The sub-workflow runs once for each item received from the parent node.

## Node Options

*   **Wait for Sub-Workflow Completion:** (Boolean)
    *   `On` (Default): The parent workflow pauses and waits for the sub-workflow to finish executing before proceeding. The output of this node will be the data returned by the sub-workflow's last node.
    *   `Off`: The parent workflow triggers the sub-workflow but continues immediately without waiting for it to finish. The output of this node will be minimal execution information, not the sub-workflow's result.

## Sub-Workflow Setup (The Called Workflow)

1.  **Trigger:** The sub-workflow *must* start with the **Execute Sub-workflow Trigger** node.
2.  **Input Data Mode (in Trigger):** Configure how the trigger expects input:
    *   `Define using fields below`: Specify named input fields and their data types. These fields will appear in the calling Execute Sub-workflow node for mapping.
    *   `Define using JSON example`: Provide example JSON to define the expected structure.
    *   `Accept all data`: Accepts any data passed without predefined structure.
3.  **Workflow Logic:** Build the rest of the sub-workflow as needed.
4.  **Output:** The data from the *last successfully executed node* in the sub-workflow is returned to the calling Execute Sub-workflow node (if `Wait for Sub-Workflow Completion` is on).
5.  **Permissions:** In the sub-workflow's settings, you can configure which other workflows are allowed to call it.

## Use Cases

*   **Reusability:** Encapsulate common sequences of nodes (e.g., custom error handling, data enrichment, specific API interactions) into a sub-workflow that can be called from multiple parent workflows.
*   **Modularity:** Break down large, complex workflows into smaller, more focused sub-workflows, improving readability and maintainability.
*   **Abstraction:** Hide the implementation details of a specific task within a sub-workflow.
*   **Parallel Processing (with Wait Off):** Trigger multiple sub-workflows concurrently, although managing their results requires separate mechanisms if needed.

## Important Considerations

*   **Data Flow:** Data is passed from the Execute Sub-workflow node to the sub-workflow's trigger. The data from the sub-workflow's *last* node is returned to the Execute Sub-workflow node's output (if waiting).
*   **Error Handling:** If the sub-workflow fails, the Execute Sub-workflow node in the parent workflow will also fail (unless error handling is configured differently).
*   **Execution Context:** Sub-workflows run as separate executions but can be linked back to the parent execution via the UI ("View sub-execution" link).
*   **Performance:** Calling sub-workflows introduces some overhead compared to having all nodes in a single workflow. For very simple, frequently called tasks, consider alternatives if performance is critical.

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executeworkflow/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executeworkflow/)*

---

## 5.3. n8nNode

# n8n Node

The n8n node (`n8n-nodes-base.n8n`) allows workflows to interact with the n8n instance itself by consuming the [n8n REST API](https://docs.n8n.io/api/).

## Credentials

Requires an [API Key](https://docs.n8n.io/api/authentication/) for authentication.

## Operations

This node provides operations to manage various aspects of the n8n instance:

*   **Audit**: `Generate` a security audit report.
*   **Credential**: `Create`, `Delete`, or `Get Schema` for credentials.
*   **Execution**: `Get`, `Get Many`, or `Delete` workflow executions.
*   **Workflow**: `Activate`, `Create`, `Deactivate`, `Delete`, `Get`, `Get Many`, or `Update` workflows.

## Parameters

Parameters vary significantly based on the selected **Resource** (Audit, Credential, Execution, Workflow) and **Operation**.

Common patterns include:

*   Specifying IDs (Credential ID, Execution ID, Workflow ID).
*   Providing JSON objects for creation or updates (e.g., Workflow Object).
*   Using filters and limits for `Get Many` operations (e.g., filter by workflow, status, tags; set limits).
*   Selecting options (e.g., Include Execution Details, Return All).

*Refer to the official documentation page for detailed parameters for each specific operation.*

## Use Cases

*   Programmatically managing workflows (activating/deactivating based on external triggers, updating workflows).
*   Managing credentials via a workflow.
*   Monitoring workflow executions (getting status, deleting old executions).
*   Generating security audits automatically.
*   Building meta-workflows that interact with the n8n instance itself.

*Source: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.n8n/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.n8n/)*

---

## 5.4. respondToWebhook

# n8n Core Node: Respond to Webhook

## Overview

The Respond to Webhook node (`n8n-nodes-base.respondtowebhook`) is specifically designed to customize the HTTP response sent back to the caller of a workflow initiated by the **Webhook** trigger node. It allows you to control the response body, status code, and headers.

## Prerequisites

This node only functions correctly when:

1.  The workflow is triggered by a **Webhook** node.
2.  The **Respond** parameter within that Webhook trigger node is set to **Using 'Respond to Webhook' node**.

## Functionality

When a workflow execution reaches a Respond to Webhook node (and the prerequisites are met), this node immediately sends the configured HTTP response back to the original webhook caller. Crucially, the workflow execution *may continue* after the response is sent, but only the *first* Respond to Webhook node encountered in an execution path will actually send a response. Subsequent Respond to Webhook nodes in the same execution are ignored.

This node operates on the *first incoming item* by default when constructing the response, unless the `Respond With` parameter is set to `All Incoming Items`.

## Node Parameters

*   **Respond With:** Determines the content and format of the response body:
    *   `All Incoming Items`: Sends all JSON items received by the node as a JSON array in the response body (Available since n8n v1.22.0).
    *   `Binary`: Sends the content of a binary file as the response body.
        *   **Response Data Source:** Specifies the field containing the binary data.
    *   `First Incoming Item`: Sends the JSON data of the first item received by the node as the response body.
    *   `JSON`: Sends a custom JSON object defined in the node.
        *   **Response Body:** Enter the JSON object.
    *   `No Data`: Sends an empty response body.
    *   `Redirect`: Sends a redirect response (typically with a 3xx status code).
        *   **Redirect URL:** The URL to redirect the caller to.
    *   `Text`: Sends plain text as the response body.
        *   **Response Body:** Enter the text content.

## Node Options

*   **Response Code:** (Integer) Sets the HTTP status code for the response (e.g., `200`, `201`, `400`, `302`). Defaults to `200`.
*   **Response Headers:** Allows adding custom HTTP headers to the response.
    *   **Specify Headers:** `Using Fields Below` (Name/Value pairs) or `Using JSON`.
*   **Put Response in Field:** (Available for `All Incoming Items` and `First Incoming Item`) Specifies a field name within the JSON response where the item data should be nested.

## Workflow Behavior Summary

*   **Webhook Node Setting:** Must be set to `Using 'Respond to Webhook' node`.
*   **Execution:** Only the *first* Respond to Webhook node encountered sends a response.
*   **No Respond Node Reached:** If the workflow finishes without hitting a Respond to Webhook node, a default `{

---

## 6.1. graphQLRequest

# GraphQL Request Node

Use the GraphQL node (`n8n-nodes-base.graphql`) to interact with APIs that use the [GraphQL](https://graphql.org/) query language. This node allows you to send queries or mutations to a GraphQL endpoint and receive the results.

## Node Parameters

*   **Authentication**: Select the authentication method required by the GraphQL endpoint (e.g., None, Basic Auth, Header Auth, OAuth2). If authentication is needed, select or create the corresponding credential.
*   **HTTP Request Method**: Choose the HTTP method for the request:
    *   **GET**: Sends the query typically as a URL parameter (less common for mutations).
    *   **POST**: Sends the query in the request body. Requires selecting a **Request Format**:
        *   **GraphQL (Raw)**: Sends the query directly in the body.
        *   **JSON**: Sends the query within a JSON structure (e.g., `{"query": "..."}`).
*   **Endpoint**: The URL of the GraphQL API endpoint.
*   **Ignore SSL Issues**: (Toggle) If enabled, bypasses SSL certificate validation errors (use with caution, mainly for testing).
*   **Query**: Enter the GraphQL query or mutation string.
*   **Response Format**: Select the desired format for the received data:
    *   **JSON**: Parses the response as JSON (most common).
    *   **String**: Returns the raw response body as a string. Requires specifying a **Response Data Property Name**.

## Headers

*   Add custom HTTP headers required by the API (e.g., `Content-Type`, custom auth tokens if not using standard credential types) as Name/Value pairs.

## AI Tool Usage

This node can be integrated into AI Agent workflows, allowing the AI to dynamically query GraphQL endpoints based on the conversation or task. Parameters like the query might be generated or filled by the AI.

## Use Cases

*   Fetching specific data structures from GraphQL APIs.
*   Performing mutations (creating, updating, deleting data) via GraphQL.
*   Integrating with services that primarily offer a GraphQL interface (e.g., GitHub API v4, various CMS platforms).

*Source: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.graphql/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.graphql/)*
*Related: [Introduction to GraphQL](https://graphql.org/learn/)*

---

## 6.2. httpRequest

# n8n Core Node: HTTP Request

## Overview

The HTTP Request node (`n8n-nodes-base.httprequest`) is one of the most versatile and fundamental core nodes in n8n. It allows workflows to interact with virtually any REST API or web service by sending HTTP requests and processing the responses. It can be used as a standard node in a workflow or as a tool within an AI Agent node.

## Functionality

This node constructs and sends HTTP requests (GET, POST, PUT, PATCH, DELETE, HEAD, OPTIONS) to a specified URL. It handles various aspects of the request, including authentication, headers, query parameters, and the request body. It then receives the response and makes it available to downstream nodes.

## Node Parameters

*   **Method:** The HTTP method to use for the request (e.g., `GET`, `POST`, `PUT`, `DELETE`).
*   **URL:** The target endpoint URL for the request. Expressions can be used here.
*   **Authentication:** Specifies how to authenticate the request.
    *   `None`: No authentication.
    *   `Predefined Credential Type`: Uses stored credentials for n8n-supported integrations (recommended when available).
    *   `Generic Credential Type`: Allows manual configuration of various authentication methods:
        *   `Basic Auth`: Username and password.
        *   `Header Auth`: Sends credentials in a custom header.
        *   `Digest Auth`: Digest access authentication.
        *   `OAuth1 API`: OAuth 1.0a authentication flow.
        *   `OAuth2 API`: OAuth 2.0 authentication flow (various grant types).
        *   `Query Auth`: Sends credentials as query parameters.
        *   `Custom Auth`: For non-standard authentication methods.
*   **Send Query Parameters:** (Toggle) If enabled, allows adding URL query parameters.
    *   **Specify Query Parameters:** `Using Fields Below` (Name/Value pairs) or `Using JSON`.
*   **Send Headers:** (Toggle) If enabled, allows adding custom HTTP headers.
    *   **Specify Headers:** `Using Fields Below` (Name/Value pairs) or `Using JSON`.
*   **Send Body:** (Toggle) If enabled (typically for POST, PUT, PATCH), allows sending a request body.
    *   **Body Content Type:** Selects the format of the body:
        *   `Form URLencoded`: Sends data as `application/x-www-form-urlencoded`.
            *   **Specify Body:** `Using Fields Below` (Name/Value pairs) or `Using Single Field` (pre-formatted string).
        *   `Form-Data`: Sends data as `multipart/form-data`, often used for file uploads.
            *   **Body Parameters:** Add parameters of type `Form Data` (Name/Value) or `n8n Binary File` (references binary data from a previous node).
        *   `JSON`: Sends data as `application/json`.
            *   **Specify Body:** `Using Fields Below` (builds JSON from Name/Value pairs) or `Using JSON` (enter raw JSON).
        *   `n8n Binary File`: Sends the raw binary data from a specified input field as the body.
            *   **Input Data Field Name:** The field containing the binary data.
        *   `Raw`: Sends a raw string body with a specified `Content-Type`.
            *   **Content Type:** The MIME type (e.g., `text/plain`, `application/xml`).
            *   **Body:** The raw text content.
*   **Import cURL Command:** Allows pasting a cURL command to automatically populate node parameters (Method, URL, Headers, Body, etc.).

## Node Options

Accessed via "Add Option".

*   **Array Format in Query Parameters:** Controls how arrays are formatted in query strings (`No Brackets`, `Brackets Only`, `Brackets with Indices`).
*   **Batching:** Configures how to handle large numbers of input items.
    *   **Items per Batch:** Number of items per request batch.
    *   **Batch Interval:** Delay (ms) between batches.
*   **Ignore SSL Issues:** (Boolean) If enabled, ignores SSL certificate errors (use with caution).
*   **Lowercase Headers:** (Boolean) If enabled (default), converts response header names to lowercase.
*   **Redirects:** Configures redirect following.
    *   **Follow Redirects:** (Boolean) Whether to follow redirects (default: true).
    *   **Max Redirects:** Maximum number of redirects to follow.
*   **Response:** Controls how the response is handled.
    *   **Include Response Headers and Status:** (Boolean) If enabled, outputs headers and status code alongside the body.
    *   **Never Error:** (Boolean) If enabled, the node succeeds even on non-2xx HTTP status codes.
    *   **Response Format:** How to parse/output the response body (`Autodetect`, `File`, `JSON`, `Text`).
*   **Pagination:** Configures automatic handling of paginated APIs (requires specific setup based on API).
*   **Proxy:** Specify a proxy server URL to route the request through.
*   **Timeout:** Maximum time (ms) to wait for a response.

## Use Cases

*   Fetching data from any public or private REST API.
*   Sending data to external services (e.g., creating records, triggering actions).
*   Interacting with webhooks that expect specific request formats.
*   Uploading files using `multipart/form-data`.
*   Integrating with services not having a dedicated n8n node.
*   Performing health checks on external services.

## Important Considerations

*   **API Documentation:** Always refer to the specific API's documentation for required endpoints, methods, authentication, headers, and body formats.
*   **Error Handling:** By default, the node fails on non-2xx responses. Use the `Never Error` option and subsequent `If` or `Switch` nodes to handle errors gracefully.
*   **Rate Limiting:** Be mindful of API rate limits. Use `Batching` options or `Wait` nodes to avoid exceeding limits.
*   **Credentials:** Use the built-in credential management for security and ease of use.

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.httprequest/)*

---

## 6.3. mqtt

# MQTT Node

Use the MQTT node (`n8n-nodes-base.mqtt`) to publish messages to an MQTT broker. This node allows n8n workflows to send data to MQTT topics, integrating with IoT devices or other services subscribed to those topics.

## Credentials

Requires [MQTT credentials](https://docs.n8n.io/integrations/builtin/credentials/mqtt/) to connect to the MQTT broker, which may include broker URL, port, username, and password.

## Operations

The primary operation is to **Send a message**.

*   **Topic**: Specify the MQTT topic to publish the message to.
*   **Message**: Enter the message payload to send. You can use expressions to include data from previous nodes.
*   **Options**:
    *   **Quality of Service (QoS)**: Select the QoS level (0, 1, or 2) for message delivery.
    *   **Retain**: (Toggle) If enabled, the broker will retain the last message published on this topic for new subscribers.

## AI Tool Usage

This node can be used within AI Agent workflows, allowing the AI to publish messages to MQTT topics based on conversational context or task requirements.

## Use Cases

*   Sending commands or data to IoT devices.
*   Publishing notifications or events to an MQTT-based messaging system.
*   Integrating n8n workflows with MQTT-enabled applications.

*Source: [https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.mqtt/](https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.mqtt/)*
*Note: There is also an [MQTT Trigger node](https://docs.n8n.io/integrations/builtin/trigger-nodes/n8n-nodes-base.mqtttrigger/) to start workflows based on messages received from MQTT topics, documented separately under Trigger Nodes.*

---

## 7.1. ftp

# FTP Node

Use the FTP node to interact with FTP (File Transfer Protocol) and SFTP (SSH File Transfer Protocol) servers. This allows you to manage files and directories remotely within your n8n workflows.

## Credentials

This node requires FTP or SFTP credentials for authentication. Configure these in your n8n instance under Credentials. For SFTP connections, ensure you use an SFTP credential type.

*   Refer to [FTP credentials documentation](https://docs.n8n.io/integrations/builtin/credentials/ftp/) for setup details.

## Operations

The FTP node supports the following file and directory operations:

*   **Delete**: Remove a file or folder from the server.
*   **Download**: Retrieve a file from the server.
*   **List**: Get a listing of the contents of a directory.
*   **Rename**: Rename or move a file or folder on the server.
*   **Upload**: Transfer a file to the server.

## Parameters by Operation

### Delete

*   **Path**: The full path to the file or folder on the server to be deleted.
*   **Options**:
    *   **Folder**: (Toggle) Enable to allow deletion of folders (not just files).
    *   **Recursive**: (Visible if Folder is enabled) If enabled, deleting a folder will also delete all its contents recursively.

### Download

*   **Path**: The full path to the file on the server to download.
*   **Put Output File in Field**: The name of the binary output field in the n8n item where the downloaded file content will be stored.

### List

*   **Path**: The path to the directory on the server whose contents you want to list.
*   **Recursive**: (Toggle) If enabled, the node lists contents recursively through subdirectories.

### Rename

*   **Old Path**: The current full path of the file or folder to be renamed/moved.
*   **New Path**: The desired new full path for the file or folder.
*   **Options**:
    *   **Create Directories**: (Toggle) If enabled, the node will automatically create any necessary parent directories for the **New Path** if they don't exist.

### Upload

*   **Path**: The destination path on the server where the file should be uploaded (including the desired filename).
*   **Binary File**: (Toggle) Select whether the source is a binary file from a previous node (enabled) or text content to be written to a new file (disabled).
    *   **Input Binary Field**: (Visible if Binary File is enabled) The name of the input field containing the binary data to upload.
    *   **File Content**: (Visible if Binary File is disabled) The text content to write into the new file on the server.

*Source: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.ftp/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.ftp/)*

---

## 7.2. readBinaryFile

# Read Binary File Node

Use the Read Binary File operation within the **Read/Write Files from Disk** node (`n8n-nodes-base.readwritefile`) to retrieve one or more files from the local filesystem of the machine running n8n.

**Note:** This node/operation is only available for self-hosted n8n instances and is not available on n8n Cloud.

## Operation: Read File(s) From Disk

This operation reads the content of specified files and outputs them as binary data items in the workflow.

### Parameters

*   **File(s) Selector**: Specify the absolute path to the file you want to read. You can also use glob patterns to select multiple files:
    *   `*`: Matches any character zero or more times (excluding path separators).
    *   `**`: Matches any character zero or more times (including path separators).
    *   `?`: Matches any single character (excluding path separators).
    *   `[]`: Matches any character within the brackets.
*   **Options**:
    *   **File Extension**: (Optional) Specify the file extension to be included in the output binary data properties.
    *   **File Name**: (Optional) Specify the file name to be included in the output binary data properties.
    *   **MIME Type**: (Optional) Specify the MIME type (e.g., `image/png`, `application/pdf`) to be included in the output binary data properties.
    *   **Put Output File in Field**: Specify the name of the field within the output item's `json` object where the binary data should be placed. The default field is `data`.

### File Locations

*   Paths are relative to the n8n installation directory by default. It is highly recommended to use **absolute paths** to avoid ambiguity.
*   If running n8n via Docker, paths refer to the filesystem *inside* the n8n container, not the host machine.

### Use Cases

*   Loading local configuration files.
*   Reading template files (e.g., HTML, text) for processing.
*   Accessing locally stored images, PDFs, or other assets needed by the workflow.
*   Processing log files.

*Source: Based on the official documentation page [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.readwritefile/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.readwritefile/)*

---

## 7.3. writeBinaryFile

# Write Binary File Node

Use the Write Binary File operation within the **Read/Write Files from Disk** node (`n8n-nodes-base.readwritefile`) to save binary data from an n8n workflow to a file on the machine where n8n is running.

**Note:** This node operation is only available for self-hosted n8n instances and is not available on n8n Cloud.

## Operation Configuration

To use this functionality, select **Write File to Disk** as the **Operation** in the node parameters.

### Parameters

*   **File Path and Name**: Specify the full destination path, including the desired filename and extension, where the binary data should be saved on the n8n server's filesystem. It is recommended to use absolute paths (e.g., `/data/output/report.pdf`).
*   **Input Binary Field**: Enter the name of the field in the incoming n8n item that contains the binary data to be written. This field typically holds data from a previous node like HTTP Request (downloading a file) or Read Binary File.

### Options

*   **Append**: (Toggle) Enable this option if you want to append the incoming binary data to an existing file at the specified path. If disabled (default), the node will overwrite any existing file or create a new one.

## Use Cases

*   Saving downloaded files (images, PDFs, documents) from web requests to the local disk.
*   Storing generated reports or data exports as files.
*   Archiving binary data processed within a workflow.

## File Locations

Be mindful of the execution environment:
*   If running n8n directly, paths are relative to the n8n installation directory unless absolute paths are used.
*   If running n8n in Docker, paths refer to the filesystem *inside* the n8n container, not the host machine, unless volumes are explicitly mapped. Using absolute paths within the container's context is recommended.

*Source: Based on the official documentation page [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.readwritefile/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.readwritefile/)*

---

## 8.1. redis

# Redis Node

Use the Redis node (`n8n-nodes-base.redis`) to interact with a Redis data store directly from your n8n workflows. This allows you to leverage Redis for caching, session management, message queuing (via Pub/Sub), and other use cases.

**Note:** You will need to configure [Redis credentials]() for authentication.

## Operations

The Redis node supports various standard Redis commands as operations:

*   **Delete**: Removes a specified key and its value from Redis (`DEL` command).
*   **Get**: Retrieves the value associated with a specified key (`GET` command).
*   **Info**: Returns generic information and statistics about the Redis server instance (`INFO` command).
*   **Increment**: Atomically increments the integer value of a key by 1. If the key does not exist, it is set to 0 before performing the operation (`INCR` command).
*   **Keys**: Returns all keys matching a specified pattern (`KEYS` command).
*   **Set**: Sets the value of a specified key. If the key already holds a value, it is overwritten (`SET` command).
*   **Publish**: Posts a message to a specified Redis channel (`PUBLISH` command).

## Parameters

Parameters vary depending on the selected **Operation**.

Common parameters include:

*   **Credentials**: Select the configured Redis credentials.
*   **Operation**: Choose the Redis command to execute (e.g., Get, Set, Delete).
*   **Key**: The Redis key to operate on.
*   **Value**: (For Set operation) The value to store for the key.
*   **Pattern**: (For Keys operation) The pattern to match keys against (e.g., `user:*`).
*   **Channel**: (For Publish operation) The channel to publish the message to.
*   **Message**: (For Publish operation) The message content to publish.

## Use Cases

*   **Caching**: Store frequently accessed data in Redis to speed up workflow execution.
*   **Session Management**: Store user session data.
*   **Rate Limiting**: Use Redis counters (`INCR`) to track and limit API calls or user actions.
*   **Distributed Locking**: Implement simple locking mechanisms.
*   **Inter-workflow Communication**: Use Pub/Sub to trigger other workflows or external processes.

*Source: Based on the official documentation page [https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.redis/](https://docs.n8n.io/integrations/builtin/app-nodes/n8n-nodes-base.redis/)*

---

## 9.1. sendEmail

# Send Email Node

Use the Send Email node (`n8n-nodes-base.sendemail`) to send emails via an SMTP server directly from your n8n workflows.

**Note:** You need to configure [SMTP credentials]() for this node.

## Operations

1.  **Send**: Sends a standard email.
2.  **Send and Wait for Response**: Sends an email and pauses the workflow execution until the recipient responds through interactive elements embedded in the email. This is useful for human-in-the-loop processes like approvals or gathering feedback.

## Parameters (Send Operation)

*   **Credential to connect with**: Select the configured SMTP credential.
*   **From Email**: The sender's email address (e.g., `"Nathan Doe" <nate@n8n.io>`).
*   **To Email**: The recipient's email address (e.g., `"Jane Smith" <jane@example.com>`).
*   **Subject**: The email subject line.
*   **Email Format**: Choose the format:
    *   **Text**: Plain text only.
    *   **HTML**: HTML content.
    *   **Both**: Sends both, allowing the recipient's client to choose.
*   **Text Body** (if Format is Text or Both): The plain text content.
*   **HTML Body** (if Format is HTML or Both): The HTML content.

## Options (Send Operation)

*   **Append n8n Attribution**: Add "This email was sent automatically with n8n" to the email footer (default: on).
*   **Attachments**: Specify the binary property name(s) containing file data to attach (comma-separated for multiple). Use nodes like `Read/Write Files from Disk` or `HTTP Request` to get binary data. Referenced in HTML using `cid:` (e.g., `<img src="cid:my_image">`).
*   **CC Email**: Carbon copy recipient(s).
*   **BCC Email**: Blind carbon copy recipient(s).
*   **Ignore SSL Issues**: Set whether to ignore TLS/SSL certificate validation errors (use with caution).
*   **Reply To**: Specify a different reply-to address.

## Parameters (Send and Wait for Response Operation)

Includes standard parameters like **From Email**, **To Email**, **Subject**, **HTML Body** (Text format not supported for waiting).

*   **Response Type**: Defines the interaction required from the recipient:
    *   **Approval**: Presents Approve/Decline buttons.
        *   **Type of Approval**: Choose `Approve Only` or `Approve / Decline`.
        *   **Button Label**: Customize button text (defaults: Approve, Decline).
        *   **Button Style**: Choose `Primary` or `Secondary` style.
    *   **Free Text**: Presents a button linking to a simple text input form.
        *   **Message Button Label**: Text for the button in the email (default: Respond).
        *   **Response Form Title**: Title for the response web form.
        *   **Response Form Description**: Text displayed on the response form.
        *   **Response Form Button Label**: Text for the submit button on the form (default: Submit).
    *   **Custom Form**: Presents a button linking to a custom-built form.
        *   Uses form elements similar to the [n8n Form Trigger](). Add fields using **Add Form Element**.
        *   Includes parameters like **Message Button Label**, **Response Form Title**, **Response Form Description**, **Response Form Button Label**.

## Options (Send and Wait for Response Operation)

*   **Limit Wait Time**: Set a maximum duration (interval or specific time) for the workflow to wait for a response before automatically resuming.
*   **Append n8n Attribution**: Add n8n attribution footer.

## Use Cases

*   Sending notifications (e.g., workflow completion, errors).
*   Sending reports or data summaries.
*   Implementing approval steps in a workflow.
*   Requesting information or feedback from users.
*   Sending personalized marketing or transactional emails.

*Source: Based on the official documentation page [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.sendemail/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.sendemail/)*

---

## 10.1. dateTime

# Date & Time

The Date & Time node manipulates date and time data and convert it to different formats.

## Timezone settings

The node relies on the timezone setting. n8n uses either:

1.  The workflow timezone, if set. Refer to Workflow settings for more information.
2.  The n8n instance timezone, if the workflow timezone isn't set. The default is `America/New York` for self-hosted instances. n8n Cloud tries to detect the instance owner's timezone when they sign up, falling back to GMT as the default. Self-hosted users can change the instance setting using Environment variables. Cloud admins can change the instance timezone in the Admin dashboard.

## Date and time in other nodes

You can work with data and time in the Code node, and in expressions in any node. n8n supports Luxon to help work with date and time in JavaScript. Refer to Date and time with Luxon for more information.

## Operations

*   **Add to a Date**: Add a specified amount of time to a date.
*   **Extract Part of a Date**: Extract part of a date, such as the year, month, or day.
*   **Format a Date**: Transform a date's format to a new format using preset options or a custom expression.
*   **Get Current Date**: Get the current date and choose whether to include the current time or not. Useful for triggering other flows and conditional logic.
*   **Get Time Between Dates**: Calculate the amount of time in specific units between two dates.
*   **Round a Date**: Round a date up or down to the nearest unit of your choice, such as month, day, or hour.
*   **Subtract From a Date**: Subtract a specified amount of time from a date.

Refer to the sections below for parameters and options specific to each operation.

## Add to a Date

Configure the node for this operation using these parameters:

*   **Date to Add To**: Enter the date you want to change.
*   **Time Unit to Add**: Select the time unit for the **Duration** parameter.
*   **Duration**: Enter the number of time units to add to the date.
*   **Output Field Name**: Enter the name of the field to output the new date to.

### Add to a Date options

This operation has one option: **Include Input Fields**. If you'd like to include all of the input fields in the output, turn this option on. If turned off, only the **Output Field Name** and its contents are output.

## Extract Part of a Date

Configure the node for this operation using these parameters:

*   **Date**: Enter the date you want to round or extract part of.
*   **Part**: Select the part of the date you want to extract. Choose from:
    *   **Year**
    *   **Month**
    *   **Week**
    *   **Day**
    *   **Hour**
    *   **Minute**
    *   **Second**
*   **Output Field Name**: Enter the name of the field to output the extracted date part to.

### Extract Part of a Date options

This operation has one option: **Include Input Fields**. If you'd like to include all of the input fields in the output, turn this option on. If turned off, only the **Output Field Name** and its contents are output.

## Format a Date

Configure the node for this operation using these parameters:

*   **Date**: Enter the date you want to format.
*   **Format**: Select the format you want to change the date to. Choose from:
    *   **Custom Format**: Enter your own custom format using Luxon's special tokens. Tokens are case-sensitive.
    *   **MM/DD/YYYY**: For `4 September 1986`, this formats the date as `09/04/1986`.
    *   **YYYY/MM/DD**: For `4 September 1986`, this formats the date as `1986/09/04`.
    *   **MMMM DD YYYY**: For `4 September 1986`, this formats the date as `September 04 1986`.
    *   **MM-DD-YYYY**: For `4 September 1986`, this formats the date as `09-04-1986`.
    *   **YYYY-MM-DD**: For `4 September 1986`, this formats the date as `1986-09-04`.
*   **Output Field Name**: Enter the name of the field to output the formatted date to.

### Format a Date options

This operation includes these options:

*   **Include Input Fields**: If you'd like to include all of the input fields in the output, turn this option on. If turned off, only the **Output Field Name** and its contents are output.
*   **From Date Format**: If the node isn't recognizing the **Date** format correctly, enter the format for that **Date** here so the node can process it properly. Use Luxon's special tokens to enter the format. Tokens are case-sensitive
*   **Use Workflow Timezone**: Whether to use the input's time zone (turned off) or the workflow's timezone (turned on).

## Get Current Date

Configure the node for this operation using these parameters:

*   **Include Current Time**: Choose whether to include the current time (turned on) or to set the time to midnight (turned off).
*   **Output Field Name**: Enter the name of the field to output the current date to.

### Get Current Date options

This operation includes these options:

*   **Include Input Fields**: If you'd like to include all of the input fields in the output, turn this option on. If turned off, only the **Output Field Name** and its contents are output.
*   **Timezone**: Set the timezone to use. If left blank, the node uses the n8n instance's timezone.

Use `GMT` for +00:00 timezone.

## Get Time Between Dates

Configure the node for this operation using these parameters:

*   **Start Date**: Enter the earlier date you want to compare.
*   **End Date**: Enter the later date you want to compare.
*   **Units**: Select the units you want to calculate the time between. You can include multiple units. Choose from:
    *   **Year**
    *   **Month**
    *   **Week**
    *   **Day**
    *   **Hour**
    *   **Minute**
    *   **Second**
    *   **Millisecond**
*   **Output Field Name**: Enter the name of the field to output the calculated time between to.

### Get Time Between Dates options

The Get Time Between Dates operation includes the **Include Input Fields** option as well as an **Output as ISO String** option. If you leave this option off, each unit you selected will return its own time difference calculation, for example:

```
timeDifference
years : 1
months : 3
days : 13
```

If you turn on the **Output as ISO String** option, the node formats the output as a single ISO duration string, for example: `P1Y3M13D`.

ISO duration format displays a format as `P<n>Y<n>M<n>DT<n>H<n>M<n>S`. `<n>` is the number for the unit after it.

*   P = period (duration). It begins all ISO duration strings.
*   Y = years
*   M = months
*   W = weeks
*   D = days
*   T = delineator between dates and times, used to avoid confusion between months and minutes
*   H = hours
*   M = minutes
*   S = seconds

Milliseconds don't get their own unit, but instead are decimal seconds. For example, 2.1 milliseconds is `0.0021S`.

## Round a Date

Configure the node for this operation using these parameters:

*   **Date**: Enter the date you'd like to round.
*   **Mode**: Choose whether to **Round Down** or **Round Up**.
*   **To Nearest**: Select the unit you'd like to round to. Choose from:
    *   **Year**
    *   **Month**
    *   **Week**
    *   **Day**
    *   **Hour**
    *   **Minute**
    *   **Second**
*   **Output Field Name**: Enter the name of the field to output the rounded date to.

### Round a Date options

This operation has one option: **Include Input Fields**. If you'd like to include all of the input fields in the output, turn this option on. If turned off, only the **Output Field Name** and its contents are output.

## Subtract From a Date

Configure the node for this operation using these parameters:

*   **Date to Subtract From**: Enter the date you want to change.
*   **Time Unit to Subtract**: Select the time unit for the **Duration** parameter.
*   **Duration**: Enter the number of time units to subtract from the date.
*   **Output Field Name**: Enter the name of the field to output the new date to.

### Subtract From a Date options

This operation has one option: **Include Input Fields**. If you'd like to include all of the input fields in the output, turn this option on. If turned off, only the **Output Field Name** and its contents are output.

## Templates and examples

*   [Get the first day of the month](https://n8n.io/workflows/1160)
*   [Get the last day of the month](https://n8n.io/workflows/1161)
*   [Get the next working day](https://n8n.io/workflows/1162)

## Related resources

View [workflow examples]() on n8n.io.

## Supported date formats

n8n supports most common date formats. If you encounter issues with a specific format, use the **Format a Date** operation with the **From Date Format** option to specify the format.

---

## 10.2. noOperation

# No Operation Node

Use the No Operation node (`n8n-nodes-base.noop`), also known as "NoOp, do nothing", when you explicitly want a point in your workflow where no action is performed on the data.

## Purpose

The primary purpose of this node is not data manipulation but workflow clarity and organization. It serves as a visual marker or endpoint for specific branches or conditions within a workflow.

## Use Cases

*   **Branch Termination**: Clearly indicate the end of a specific logic path, especially in IF or Switch nodes, where one branch might not require further action.
*   **Workflow Readability**: Improve the visual understanding of complex workflows by marking points where a flow intentionally stops or pauses before potentially merging later.
*   **Debugging**: Temporarily place a NoOp node to observe data flow up to a certain point without interference.
*   **Placeholders**: Use as a placeholder during workflow development where a node will eventually be added.

## Parameters

This node has no configurable parameters as its function is simply to pass incoming data through unchanged.

*Source: Based on the official documentation page [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.noop/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.noop/)*

---

## 10.3. wait

# n8n Core Node: Wait

## Overview

The Wait node (`n8n-nodes-base.wait`) provides functionality to pause a workflow execution until a specific condition is met. This is crucial for scenarios requiring delays, scheduling actions for a future time, or waiting for external events like webhook calls or form submissions.

When paused, the workflow execution state is offloaded (typically to the database), and resources are freed up. When the resume condition is met, the state is reloaded, and the workflow continues from the Wait node.

## Operations (Resume Conditions)

The Wait node can resume execution based on one of the following conditions selected in the **Resume** parameter:

1.  **After Time Interval:** Pauses the workflow for a defined duration.
    *   **Wait Amount:** (Number) The duration to wait.
    *   **Wait Unit:** (Seconds, Minutes, Hours, Days) The unit for the Wait Amount.

2.  **At Specified Time:** Pauses the workflow until a specific date and time.
    *   **Date and Time:** (DateTime Picker) The exact date and time to resume execution. Uses the n8n instance's timezone.

3.  **On Webhook Call:** Pauses the workflow until a unique, execution-specific webhook URL is called.
    *   **Resume URL:** The node generates a unique URL accessible via the expression `$execution.resumeUrl`. This URL must be sent to the external service that will trigger the resume.
    *   **Authentication:** (None, Basic Auth, Header Auth, JWT Auth) Configures authentication required to call the resume URL.
    *   **HTTP Method:** (GET, POST, PUT, etc.) The expected HTTP method for the resume call.
    *   **Respond:** (Immediately, When Last Node Finishes, Using 'Respond to Webhook' Node) Configures how the Wait node responds to the resume webhook call itself.
    *   **Limit Wait Time:** (Optional) Sets a maximum duration or a specific time after which the workflow resumes automatically if the webhook hasn't been called.
    *   **Options:** Additional settings like `Binary Property`, `Ignore Bots`, `IP(s) Whitelist`, `Raw Body`, `Response Headers`, `Webhook Suffix`.

4.  **On Form Submitted:** Pauses the workflow, presents a simple web form at a unique URL (also available via `$execution.resumeUrl`), and waits for a user to submit the form.
    *   **Form Title:** Title displayed on the form page.
    *   **Form Description:** Text displayed below the title.
    *   **Form Fields:** Define the input fields for the form (Label, Type: Text, Textarea, Number, Date, Password, Dropdown List; Required toggle).
    *   **Respond When:** (Form Is Submitted, Workflow Finishes, Using 'Respond to Webhook' Node) Configures when the response is sent back to the user submitting the form.
    *   **Limit Wait Time:** (Optional) Sets a maximum duration or a specific time after which the workflow resumes automatically if the form hasn't been submitted.

## Use Cases

*   **Scheduled Actions:** Delaying part of a workflow until a specific time or after an interval (e.g., sending follow-up emails).
*   **Rate Limiting:** Introducing delays between API calls to avoid exceeding rate limits.
*   **Waiting for External Events:** Pausing until an external system confirms a task completion via a webhook call.
*   **Human-in-the-Loop:** Waiting for user input or approval via a simple web form.
*   **Polling (Less Ideal):** While possible to create polling loops with Wait, it's often less efficient than using trigger nodes or webhooks if available.

## Important Considerations

*   **Offloading:** Waiting executions are saved to the database, reducing server load for long waits.
*   **Resume URL (`$execution.resumeUrl`):** This URL is unique per execution for the Webhook and Form modes. It must be correctly communicated to the entity expected to trigger the resume.
*   **Timezone:** Time-based waits (`At Specified Time`, time limits) use the timezone configured for the n8n instance.
*   **Webhook Limitations:** The resume URL changes if a workflow execution is manually rerun partially. Ensure the system calling the webhook receives the correct URL from the relevant execution.
*   **Error Handling:** If the Wait node fails (e.g., invalid time format), the workflow will error unless specific error handling is implemented.

*Reference: [https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.wait/](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.wait/)*

---

## 11.1.1. basicLLMChain

# Basic LLM Chain node

Use the Basic LLM Chain node to set the prompt that the model will use along with setting an optional parser for the response.

On this page, you'll find the node parameters for the Basic LLM Chain node and links to more resources.

## Node parameters

### Prompt

Select how you want the node to construct the prompt (also known as the user's query or input from the chat).

Choose from:

*   **Take from previous node automatically**: If you select this option, the node expects an input from a previous node called `chatInput`.
*   **Define below**: If you select this option, provide either static text or an expression for dynamic content to serve as the prompt in the **Prompt (User Message)** field.

### Require Specific Output Format

This parameter controls whether you want the node to require a specific output format. When turned on, n8n prompts you to connect one of these output parsers to the node:

*   Auto-fixing Output Parser
*   Item List Output Parser
*   Structured Output Parser

## Chat Messages

Use **Chat Messages** when you're using a chat model to set a message.

n8n ignores these options if you don't connect a chat model. Select the **Type Name or ID** you want the node to use:

#### AI

Enter a sample expected response in the **Message** field. The model will try to respond in the same way in its messages.

#### System

Enter a system **Message** to include with the user input to help guide the model in what it should do.

Use this option for things like defining tone, for example: `Always respond talking like a pirate`.

#### User

Enter a sample user input. Using this with the AI option can help improve the output of the agent. Using both together provides a sample of an input and expected response (the **AI Message**) for the model to follow.

Select one of these input types:

*   **Text**: Enter a sample user input as a text **Message**.
*   **Image (Binary)**: Select a binary input from a previous node. Enter the **Image Data Field Name** to identify which binary field from the previous node contains the image data.
*   **Image (URL)**: Use this option to feed an image in from a URL. Enter the **Image URL**.

For both the **Image** types, select the **Image Details** to control how the model processes the image and generates its textual understanding. Choose from:

*   **Auto**: The model uses the auto setting, which looks at the image input size and decide if it should use the Low or High setting.
*   **Low**: The model receives a low-resolution 512px x 512px version of the image and represents the image with a budget of 65 tokens. This allows the API to return faster responses and consume fewer input tokens. Use this option for use cases that don't require high detail.
*   **High**: The model can access the low-resolution image and then creates detailed crops of input images as 512px squares based on the input image size. Each of the detailed crops uses twice the token budget (65 tokens) for a total of 129 tokens. Use this option for use cases that require high detail.

## Templates and examples

(Refer to n8n Basic LLM Chain integrations page)

## Related resources

Refer to LangChain's documentation on Basic LLM Chains for more information about the service.

View n8n's Advanced AI documentation.

## AI glossary

*   **completion**: Completions are the responses generated by a model like GPT.
*   **hallucinations**: Hallucination in AI is when an LLM (large language model) mistakenly perceives patterns or objects that don't exist.
*   **vector database**: A vector database stores mathematical representations of information. Use with embeddings and retrievers to create a database that your AI can access when answering questions.
*   **vector store**: A vector store, or vector database, stores mathematical representations of information. Use with embeddings and retrievers to create a database that your AI can access when answering questions.

## Common issues

Here are some common errors and issues with the Basic LLM Chain node and steps to resolve or troubleshoot them.

### No prompt specified error

This error displays when the **Prompt** is empty or invalid.

You might see this error in one of two scenarios:

1.  When you've set the **Prompt** to **Define below** and haven't entered anything in the **Text** field.
    *   To resolve, enter a valid prompt in the **Text** field.
2.  When you've set the **Prompt** to **Connected Chat Trigger Node** and the incoming data has no field called `chatInput`.
    *   The node expects the `chatInput` field. If your previous node doesn't have this field, add an Edit Fields (Set) node to edit an incoming field name to `chatInput`.

---

## 11.1.2. retrievalQAChain

# Question and Answer Chain node

Use the Question and Answer Chain node (also known as Retrieval Q&A Chain) to use a vector store as a retriever.

On this page, you'll find the node parameters for the Question and Answer Chain node, and links to more resources.

## Node parameters

### Query

The question you want to ask the AI, which will be answered based on the context retrieved from the connected vector store or retriever.

## Node Connections

This node typically requires connections to:

1.  **Language Model**: An LLM node (like OpenAI Chat Model, Anthropic Chat Model, etc.) to generate the answer based on the query and retrieved context.
2.  **Retriever**: A retriever node (like Vector Store Retriever, Workflow Retriever, etc.) which fetches relevant documents or data based on the query. This provides the context for the language model.

## Templates and examples

*   Ask questions about a PDF using AI
*   AI Crew to Automate Fundamental Stock Analysis - Q&A Workflow

(Refer to the n8n documentation page for template details)

## Related resources

*   Refer to [LangChain's documentation on retrieval chains](https://python.langchain.com/v0.1/docs/modules/chains/) for examples of how LangChain can use a vector store as a retriever.
*   View n8n's [Advanced AI](https://docs.n8n.io/advanced-ai/) documentation.

## Common issues

For common errors or issues and suggested resolution steps, refer to [Common Issues](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainretrievalqa/common-issues/).

## AI glossary

*   **completion**: Completions are the responses generated by a model like GPT.
*   **hallucinations**: Hallucination in AI is when an LLM (large language model) mistakenly perceives patterns or objects that don't exist.
*   **vector database**: A vector database stores mathematical representations of information. Use with embeddings and retrievers to create a database that your AI can access when answering questions.
*   **vector store**: A vector store, or vector database, stores mathematical representations of information. Use with embeddings and retrievers to create a database that your AI can access when answering questions.

---

## 11.1.3. summarizationChain

# Summarization Chain node

Use the Summarization Chain node to summarize multiple documents.

On this page, you'll find the node parameters for the Summarization Chain node, and links to more resources.

## Node parameters

Choose the type of data you need to summarize in **Data to Summarize**. The data type you choose determines the other node parameters.

*   **Use Node Input (JSON)** and **Use Node Input (Binary)**: Summarize the data coming into the node from the workflow.
    *   You can configure the **Chunking Strategy**: Choose what strategy to use to define the data chunk sizes.
        *   If you choose **Simple (Define Below)** you can then set **Characters Per Chunk** and **Chunk Overlap (Characters)**.
        *   Choose **Advanced** if you want to connect a Text Splitter sub-node that provides more configuration options (e.g., Character Text Splitter, Recursive Character Text Splitter, Token Splitter).
*   **Use Document Loader**: Summarize data provided by a connected Document Loader sub-node (e.g., Default Document Loader, GitHub Document Loader).

## Node Connections

This node typically requires connections to:

1.  **Language Model**: An LLM node (like OpenAI Chat Model, Anthropic Chat Model, etc.) to perform the summarization.
2.  **(Optional) Text Splitter**: If using the **Advanced** chunking strategy, connect a Text Splitter sub-node.
3.  **(Optional) Document Loader**: If using the **Use Document Loader** option, connect a Document Loader sub-node.

## Node Options

You can configure the summarization method and prompts. Select **Add Option** > **Summarization Method and Prompts**.

Options in **Summarization Method**:

*   **Map Reduce**: This is the recommended option. It summarizes each chunk individually (map step) and then combines these summaries into a final summary (reduce step). Learn more about [Map Reduce](https://python.langchain.com/v0.1/docs/modules/chains/document/map_reduce/) in the LangChain documentation.
*   **Refine**: This method iterates through the input documents, updating the summary based on each document. Learn more about [Refine](https://python.langchain.com/v0.1/docs/modules/chains/document/refine/) in the LangChain documentation.
*   **Stuff**: This method simply stuffs all documents into the prompt. It's the simplest method but can fail if the total document size exceeds the model's context window. Learn more about [Stuff](https://python.langchain.com/v0.1/docs/modules/chains/document/stuff/) in the LangChain documentation.

You can customize the **Individual Summary Prompts** (used in Map Reduce and Refine) and the **Final Prompt to Combine** (used in Map Reduce). There are examples in the node. You must include the `"{text}"` placeholder.

## Templates and examples

(Refer to the n8n documentation page for potential templates)

## Related resources

*   Refer to [LangChain's documentation on summarization](https://python.langchain.com/v0.1/docs/modules/chains/document/) for more information about the service.
*   View n8n's [Advanced AI](https://docs.n8n.io/advanced-ai/) documentation.

## AI glossary

*   **completion**: Completions are the responses generated by a model like GPT.
*   **hallucinations**: Hallucination in AI is when an LLM (large language model) mistakenly perceives patterns or objects that don't exist.
*   **vector database**: A vector database stores mathematical representations of information. Use with embeddings and retrievers to create a database that your AI can access when answering questions.
*   **vector store**: A vector store, or vector database, stores mathematical representations of information. Use with embeddings and retrievers to create a database that your AI can access when answering questions.

---

## 11.1.4. sentimentAnalysis

# Sentiment Analysis node

Use the Sentiment Analysis node to analyze the sentiment of incoming text data.

The language model uses the **Sentiment Categories** defined in the node options to determine each item's sentiment.

## Node parameters

*   **Text to Analyze**: Defines the input text for sentiment analysis. This is typically an expression referencing a field from the input items (e.g., `{{ $json.chatInput }}` or `{{ $json.content }}`). By default, it expects a field named `text`.

## Node Connections

This node typically requires a connection to:

1.  **Language Model**: An LLM node (like OpenAI Chat Model, Anthropic Chat Model, etc.) to perform the sentiment analysis.

## Node options

*   **Sentiment Categories**: Define the categories used for classification. 
    *   Defaults to `Positive, Neutral, Negative`.
    *   Can be customized (e.g., `Very Positive, Positive, Neutral, Negative, Very Negative`) for more granular analysis.
*   **Include Detailed Results**: If enabled, the output includes estimated sentiment strength and confidence scores from the language model.
*   **System Prompt Template**: Allows customization of the system prompt used for analysis. Must include the `{categories}` placeholder.
*   **Enable Auto-Fixing**: If enabled, the node attempts to automatically correct model outputs that don't match the expected format by resubmitting the request with the parsing error information.

## Usage Notes

*   **Model Temperature Setting**: It is strongly recommended to set the temperature of the connected language model to 0 or a very low value for more consistent and deterministic results.
*   **Language Considerations**: Performance depends on the language model's support for the input text language.
*   **Processing Large Volumes**: Consider splitting large texts into smaller chunks before analysis.
*   **Iterative Refinement**: The system prompt and categories might need adjustments for complex tasks to achieve desired accuracy.

## Example Usage

### Basic Sentiment Analysis

1.  Connect a data source (e.g., RSS Feed) to the node.
2.  Set **Text to Analyze** to the relevant field (e.g., `{{ $json.content }}`).
3.  Use default categories (`Positive, Neutral, Negative`).
4.  Route outputs based on the determined sentiment.

### Custom Category Analysis

1.  Modify **Sentiment Categories** (e.g., `Excited, Happy, Neutral, Disappointed, Angry`).
2.  Adjust the downstream workflow to handle these custom categories.

## Related resources

*   View n8n's [Advanced AI](https://docs.n8n.io/advanced-ai/) documentation.

## AI glossary

*   **completion**: Completions are the responses generated by a model like GPT.
*   **hallucinations**: Hallucination in AI is when an LLM (large language model) mistakenly perceives patterns or objects that don't exist.
*   **vector database**: A vector database stores mathematical representations of information. Use with embeddings and retrievers to create a database that your AI can access when answering questions.
*   **vector store**: A vector store, or vector database, stores mathematical representations of information. Use with embeddings and retrievers to create a database that your AI can access when answering questions.

---

## 11.1.5. textClassifier

# Text Classifier node

Use the Text Classifier node to classify (categorize) incoming data based on predefined categories.

On this page, you'll find the node parameters for the Text Classifier node, and links to more resources.

## Node parameters

*   **Input Prompt**: Defines the input text to classify. This is typically an expression referencing a field from the input items (e.g., `{{ $json.chatInput }}` or `{{ $json.text }}`). By default, it references the `text` field.
*   **Categories**: Define the categories for classification. Each category requires:
    *   **Name**: The label for the category.
    *   **Description**: A description explaining the category to the language model, crucial if the meaning isn't obvious.

## Node Connections

This node typically requires a connection to:

1.  **Language Model**: An LLM node (like OpenAI Chat Model, Anthropic Chat Model, etc.) to perform the classification.

## Node options

*   **Allow Multiple Classes To Be True**: 
    *   If turned off (default), the classifier outputs only a single, best-matching category per item.
    *   If turned on, the model can assign multiple categories to an item if applicable.
*   **When No Clear Match**: Defines behavior when the model cannot confidently assign any category:
    *   **Discard Item** (default): The item is dropped from the workflow.
    *   **Output on Extra, 'Other' Branch**: Creates a separate output branch named 'Other' where such items are routed.
*   **System Prompt Template**: Allows customization of the system prompt used for classification. Must include the `{categories}` placeholder.
*   **Enable Auto-Fixing**: If enabled, the node attempts to automatically correct model outputs that don't match the expected format by resubmitting the request with the parsing error information.

## Related resources

*   View n8n's [Advanced AI](https://docs.n8n.io/advanced-ai/) documentation.

## AI glossary

*   **completion**: Completions are the responses generated by a model like GPT.
*   **hallucinations**: Hallucination in AI is when an LLM (large language model) mistakenly perceives patterns or objects that don't exist.
*   **vector database**: A vector database stores mathematical representations of information. Use with embeddings and retrievers to create a database that your AI can access when answering questions.
*   **vector store**: A vector store, or vector database, stores mathematical representations of information. Use with embeddings and retrievers to create a database that your AI can access when answering questions.

---

## 11.2.1. agent

# AI Agent node

An AI agent is an autonomous system within n8n that receives data, makes rational decisions based on its configuration and available tools, and acts within its environment (accessible data and services) to achieve specific goals.

The AI Agent node uses external tools (connected as sub-nodes) and APIs to perform actions and retrieve information. It can understand the capabilities of different tools and determine which tool to use depending on the task or user input.

## Node Connections

*   **Language Model**: Requires a connection to an LLM node (e.g., OpenAI Chat Model, Anthropic Chat Model) to power its decision-making.
*   **Tools**: Requires at least one Tool sub-node to be connected (e.g., Calculator, Code Tool, SerpAPI, Workflow Tool, Vector Store Tool). The agent uses these tools to interact with the environment and perform actions.
*   **(Optional) Memory**: Can be connected to a Memory sub-node (e.g., Simple Memory, Redis Chat Memory) to retain context across multiple interactions.

## Agent Type

Prior to n8n version 1.82.0, the AI Agent node allowed selecting different agent types (like Conversational, ReAct, etc.). This selection has been removed.

All current AI Agent nodes function as a **Tools Agent**. This agent type implements LangChain's tool calling interface, allowing it to effectively select and use the connected tools based on the input and goal. Workflows created with older versions set to 'Tools Agent' should continue to function as expected.

*(Note: While the main node functions as a Tools Agent, the documentation previously listed specific agent types like Conversational, OpenAI Functions, Plan and Execute, ReAct, and SQL Agent. These might represent specific configurations or prompt strategies achievable with the Tools Agent or potentially deprecated concepts. Refer to LangChain documentation for advanced agent strategies.)*

## Templates and examples

*   AI agent chat

(Refer to the n8n documentation page for template details)

## Related resources

*   Refer to [LangChain's documentation on agents](https://python.langchain.com/v0.1/docs/modules/agents/) for more information about the service.
*   Read the [n8n blog introduction to AI agents](https://n8n.io/blog/ai-agents/).
*   View n8n's [Advanced AI](https://docs.n8n.io/advanced-ai/) documentation.

## Common issues

For common errors or issues and suggested resolution steps, refer to [Common Issues](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/common-issues/).

## AI glossary

*   **completion**: Completions are the responses generated by a model like GPT.
*   **hallucinations**: Hallucination in AI is when an LLM (large language model) mistakenly perceives patterns or objects that don't exist.
*   **vector database**: A vector database stores mathematical representations of information. Use with embeddings and retrievers to create a database that your AI can access when answering questions.
*   **vector store**: A vector store, or vector database, stores mathematical representations of information. Use with embeddings and retrievers to create a database that your AI can access when answering questions.

---

## 11.3.1. simpleVectorStore

# Simple Vector Store node

Use the Simple Vector Store node to store and retrieve vector embeddings directly within n8n's in-app memory. This node acts as an in-memory vector database.

**Important:**

*   **For Development Use Only:** This node stores data transiently in memory. All data is lost when the n8n instance restarts or may be purged under low-memory conditions. It is **not recommended** for production use.
*   **Different from AI Memory Nodes:** This node provides vector storage, distinct from conversational memory nodes like Simple Memory which store chat history.
*   **Parameter Resolution in Sub-nodes:** When used as a sub-node or connected to one, expressions within its parameters resolve only based on the *first* incoming item, not for each item individually.

On this page, you'll find usage patterns, memory management details, and node parameters.

## Node Usage Patterns

1.  **Regular Node (Insert/Retrieve):** Use directly in the workflow to insert documents (creating embeddings) or retrieve documents via similarity search using a prompt.
2.  **Direct Tool for AI Agent:** Connect to the `tool` input of an AI Agent node. The agent can then query the vector store as one of its available tools.
3.  **Retriever for Chains:** Connect to a `Vector Store Retriever` sub-node, which in turn connects to a chain node (like `Question and Answer Chain`). The retriever fetches relevant documents from the store based on the chain's input.
4.  **Tool for Vector Store Q&A:** Connect to a `Vector Store Question Answer Tool` sub-node, which then connects to an AI Agent. This allows the agent to get summarized answers based on the vector store content, rather than just raw documents.

## Memory Management

The Simple Vector Store includes mechanisms to manage memory usage:

*   Automatically cleans up older stores under memory pressure.
*   Removes inactive stores (configurable time limit).
*   Isolates storage per workflow (based on workflow ID and Memory Key).

### Configuration Options (Environment Variables)

*   `N8N_LANGCHAIN_VECTORSTORE_MEMORY_MAX_MB`: Sets the maximum memory (in MB) the store can use. Default: `-1` (no limit) for self-hosted, `100` for n8n Cloud.
*   `N8N_LANGCHAIN_VECTORSTORE_MEMORY_MAX_AGE_DAYS`: Sets the maximum inactivity period (in days) before a store is removed. Default: `-1` (no time limit) for self-hosted, `7` for n8n Cloud.

## Node Parameters

### Operation Mode

Select the node's function:

*   **Get Many:** Retrieve multiple documents based on prompt similarity.
*   **Insert Documents:** Add new documents to the store (embeddings are generated).
*   **Retrieve Documents (As Vector Store for Chain/Tool):** Provide the store connection for a Retriever sub-node.
*   **Retrieve Documents (As Tool for AI Agent):** Expose the store as a queryable tool for an AI Agent.

### Parameters by Mode

**1. Get Many:**

*   **Memory Key:** Unique identifier for this vector store within the workflow.
*   **Embeddings:** Select the Embeddings model sub-node to use.
*   **Prompt:** The text query for similarity search.
*   **Limit:** Maximum number of similar documents to return.

**2. Insert Documents:**

*   **Memory Key:** Unique identifier for this vector store within the workflow.
*   **Embeddings:** Select the Embeddings model sub-node to use for creating document embeddings.
*   **Text Splitter:** (Optional) Select a Text Splitter sub-node to chunk large documents before embedding.
*   **Clear Store:** If enabled, deletes all existing data for this Memory Key before inserting new documents.

**3. Retrieve Documents (As Vector Store for Chain/Tool):**

*   **Memory Key:** Unique identifier for the vector store to connect to.
*   **Embeddings:** Select the Embeddings model sub-node (must match the one used for insertion).

**4. Retrieve Documents (As Tool for AI Agent):**

*   **Name:** A descriptive name for the tool (used by the agent).
*   **Description:** Explain the tool's purpose and content to the agent.
*   **Memory Key:** Unique identifier for the vector store to query.
*   **Embeddings:** Select the Embeddings model sub-node (must match the one used for insertion).
*   **Limit:** Maximum number of similar documents to retrieve per query.

## Related resources

*   Refer to [LangChain's Memory Vector Store documentation](https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/) for more information about vector stores.
*   View n8n's [Advanced AI](https://docs.n8n.io/advanced-ai/) documentation.

## AI glossary

*   **completion**: Completions are the responses generated by a model like GPT.
*   **embeddings**: Numerical representations of text, capturing semantic meaning.
*   **hallucinations**: Hallucination in AI is when an LLM (large language model) mistakenly perceives patterns or objects that don't exist.
*   **vector database**: A database optimized for storing and querying vector embeddings.
*   **vector store**: A component (like this node) that stores and allows retrieval of vector embeddings.

---

## 11.3.2. pgVectorVectorStore

# PGVector Vector Store node

Use the PGVector Vector Store node to interact with vector data stored in a PostgreSQL database that has the [PGVector extension](https://github.com/pgvector/pgvector) enabled.

This node allows you to insert documents (creating embeddings), retrieve documents via similarity search, provide the store connection to a retriever sub-node, or connect the store directly as a tool for an AI Agent.

**Prerequisites:**

*   A PostgreSQL database instance.
*   The `pgvector` extension installed and enabled in your database.
*   Postgres credentials configured in n8n.

**Note on Parameter Resolution in Sub-nodes:** When used as a sub-node or connected to one, expressions within its parameters resolve only based on the *first* incoming item, not for each item individually.

On this page, you'll find usage patterns and node parameters.

## Node Usage Patterns

1.  **Regular Node (Insert/Retrieve):** Use directly in the workflow to insert documents (creating embeddings) into a specified table or retrieve documents via similarity search using a prompt.
2.  **Direct Tool for AI Agent:** Connect to the `tool` input of an AI Agent node. The agent can then query the PGVector store as one of its available tools, using the provided name and description.
3.  **Retriever for Chains:** Connect to a `Vector Store Retriever` sub-node, which in turn connects to a chain node (like `Question and Answer Chain`). The retriever fetches relevant documents from the specified PGVector table based on the chain's input.
4.  **Tool for Vector Store Q&A:** Connect to a `Vector Store Question Answer Tool` sub-node, which then connects to an AI Agent. This allows the agent to get summarized answers based on the PGVector store content.

## Node Parameters

### Credentials

Select your configured PostgreSQL credentials.

### Operation Mode

Select the node's function:

*   **Get Many:** Retrieve multiple documents based on prompt similarity.
*   **Insert Documents:** Add new documents to the store (embeddings are generated).
*   **Retrieve Documents (As Vector Store for Chain/Tool):** Provide the store connection for a Retriever sub-node.
*   **Retrieve Documents (As Tool for AI Agent):** Expose the store as a queryable tool for an AI Agent.

### Parameters by Mode

**1. Get Many:**

*   **Table Name:** The name of the PGVector table to query.
*   **Embeddings:** Select the Embeddings model sub-node to use for the prompt.
*   **Prompt:** The text query for similarity search.
*   **Limit:** Maximum number of similar documents to return.
*   **(Optional) Metadata Filter:** Filter results based on metadata fields (uses AND logic if multiple filters are applied).

**2. Insert Documents:**

*   **Table Name:** The name of the PGVector table to insert into.
*   **Embeddings:** Select the Embeddings model sub-node to use for creating document embeddings.
*   **Text Splitter:** (Optional) Select a Text Splitter sub-node to chunk large documents before embedding.

**3. Retrieve Documents (As Vector Store for Chain/Tool):**

*   **Table Name:** The name of the PGVector table to connect to.
*   **Embeddings:** Select the Embeddings model sub-node (must match the one used for insertion).

**4. Retrieve Documents (As Tool for AI Agent):**

*   **Name:** A descriptive name for the tool (used by the agent).
*   **Description:** Explain the tool's purpose and content to the agent.
*   **Table Name:** The name of the PGVector table to query.
*   **Embeddings:** Select the Embeddings model sub-node (must match the one used for insertion).
*   **Limit:** Maximum number of similar documents to retrieve per query.

## Node Options

*   **Collection:** (Optional) Use collections to separate datasets within PGVector. This creates additional tables/columns.
    *   **Use Collection:** Enable/disable collection usage.
    *   **Collection Name:** Name of the collection.
    *   **Collection Table Name:** Name of the table storing collection information.
*   **Column Names:** (Optional) Specify custom column names if they differ from the defaults.
    *   **ID Column Name**
    *   **Vector Column Name**
    *   **Content Column Name**
    *   **Metadata Column Name**

## Related resources

*   Refer to [LangChain's PGVector documentation](https://python.langchain.com/v0.1/docs/integrations/vectorstores/pgvector/) for more information.
*   View n8n's [Advanced AI](https://docs.n8n.io/advanced-ai/) documentation.
*   Check the [n8n Self-hosted AI Starter Kit](https://github.com/n8n-io/ai-starter-kit) for examples using PGVector.

---

## 11.3.3. pineconeVectorStore

# Pinecone Vector Store node

Use the Pinecone Vector Store node to interact with your vector data stored in a [Pinecone](https://www.pinecone.io/) index. Pinecone is a managed vector database service.

This node allows you to insert, update, or retrieve documents (via similarity search) from a specified Pinecone index. It can also provide the store connection to a retriever sub-node or connect directly as a tool for an AI Agent.

**Prerequisites:**

*   A Pinecone account and API key.
*   A Pinecone index created in your account.
*   Pinecone credentials configured in n8n.

**Note on Parameter Resolution in Sub-nodes:** When used as a sub-node or connected to one, expressions within its parameters resolve only based on the *first* incoming item, not for each item individually.

On this page, you'll find usage patterns and node parameters.

## Node Usage Patterns

1.  **Regular Node (Insert/Update/Retrieve):** Use directly in the workflow to insert, update (by ID), or retrieve documents via similarity search from a specified index.
2.  **Direct Tool for AI Agent:** Connect to the `tool` input of an AI Agent node. The agent can then query the Pinecone index as one of its available tools.
3.  **Retriever for Chains:** Connect to a `Vector Store Retriever` sub-node, which in turn connects to a chain node (like `Question and Answer Chain`). The retriever fetches relevant documents from the specified Pinecone index based on the chain's input.
4.  **Tool for Vector Store Q&A:** Connect to a `Vector Store Question Answer Tool` sub-node, which then connects to an AI Agent. This allows the agent to get summarized answers based on the Pinecone index content.

## Node Parameters

### Credentials

Select your configured Pinecone credentials.

### Operation Mode

Select the node's function:

*   **Get Many:** Retrieve multiple documents based on prompt similarity.
*   **Insert Documents:** Add new documents to the index (embeddings are generated).
*   **Retrieve Documents (As Vector Store for Chain/Tool):** Provide the store connection for a Retriever sub-node.
*   **Retrieve Documents (As Tool for AI Agent):** Expose the store as a queryable tool for an AI Agent.
*   **Update Documents:** Update existing documents in the index by their ID.

### Parameters by Mode

**1. Get Many:**

*   **Pinecone Index:** Select or enter the name of the Pinecone index to query.
*   **Embeddings:** Select the Embeddings model sub-node to use for the prompt.
*   **Prompt:** The text query for similarity search.
*   **Limit:** Maximum number of similar documents to return.
*   **(Optional) Metadata Filter:** Filter results based on metadata fields (uses AND logic if multiple filters are applied).
*   **(Optional) Pinecone Namespace:** Specify a namespace within the index to search.

**2. Insert Documents:**

*   **Pinecone Index:** Select or enter the name of the Pinecone index to insert into.
*   **Embeddings:** Select the Embeddings model sub-node to use for creating document embeddings.
*   **Text Splitter:** (Optional) Select a Text Splitter sub-node to chunk large documents before embedding.
*   **(Optional) Pinecone Namespace:** Specify a namespace within the index to insert into.
*   **(Optional) Clear Namespace:** If enabled, deletes all data from the specified namespace before inserting new documents.

**3. Retrieve Documents (As Vector Store for Chain/Tool):**

*   **Pinecone Index:** Select or enter the name of the Pinecone index to connect to.
*   **Embeddings:** Select the Embeddings model sub-node (must match the one used for insertion).
*   **(Optional) Pinecone Namespace:** Specify the namespace within the index.

**4. Retrieve Documents (As Tool for AI Agent):**

*   **Name:** A descriptive name for the tool (used by the agent).
*   **Description:** Explain the tool's purpose and content to the agent.
*   **Pinecone Index:** Select or enter the name of the Pinecone index to query.
*   **Embeddings:** Select the Embeddings model sub-node (must match the one used for insertion).
*   **Limit:** Maximum number of similar documents to retrieve per query.
*   **(Optional) Pinecone Namespace:** Specify the namespace within the index to query.

**5. Update Documents:**

*   **Pinecone Index:** Select or enter the name of the Pinecone index containing the document.
*   **Embeddings:** Select the Embeddings model sub-node.
*   **ID:** The ID of the vector/document entry to update.
*   **(Optional) Pinecone Namespace:** Specify the namespace containing the document.

## Related resources

*   Refer to [LangChain's Pinecone documentation](https://python.langchain.com/v0.1/docs/integrations/vectorstores/pinecone/) for more information.
*   View n8n's [Advanced AI](https://docs.n8n.io/advanced-ai/) documentation.
*   See the example workflow: [Populate a Pinecone vector database from a website](https://docs.n8n.io/advanced-ai/examples/vector-store-website/).

## AI glossary

*   **completion**: Completions are the responses generated by a model like GPT.
*   **embeddings**: Numerical representations of text, capturing semantic meaning.
*   **hallucinations**: Hallucination in AI is when an LLM (large language model) mistakenly perceives patterns or objects that don't exist.
*   **vector database**: A database optimized for storing and querying vector embeddings (like Pinecone).
*   **vector store**: A component (like this node) that interfaces with a vector database.

---

## 11.3.4. qdrantVectorStore

# Qdrant Vector Store node

Use the Qdrant Vector Store node to interact with your vector data stored in a [Qdrant](https://qdrant.tech/) collection. Qdrant is an open-source vector database.

This node allows you to insert documents (creating embeddings), retrieve documents via similarity search, provide the store connection to a retriever sub-node, or connect the store directly as a tool for an AI Agent.

**Prerequisites:**

*   A Qdrant instance (cloud or self-hosted).
*   Qdrant credentials (URL and optionally API Key) configured in n8n.

**Note on Parameter Resolution in Sub-nodes:** When used as a sub-node or connected to one, expressions within its parameters resolve only based on the *first* incoming item, not for each item individually.

On this page, you'll find usage patterns and node parameters.

## Node Usage Patterns

1.  **Regular Node (Insert/Retrieve):** Use directly in the workflow to insert documents (creating embeddings) into a specified collection or retrieve documents via similarity search using a prompt.
2.  **Direct Tool for AI Agent:** Connect to the `tool` input of an AI Agent node. The agent can then query the Qdrant collection as one of its available tools.
3.  **Retriever for Chains:** Connect to a `Vector Store Retriever` sub-node, which in turn connects to a chain node (like `Question and Answer Chain`). The retriever fetches relevant documents from the specified Qdrant collection based on the chain's input.
4.  **Tool for Vector Store Q&A:** Connect to a `Vector Store Question Answer Tool` sub-node, which then connects to an AI Agent. This allows the agent to get summarized answers based on the Qdrant collection content.

## Node Parameters

### Credentials

Select your configured Qdrant credentials.

### Operation Mode

Select the node's function:

*   **Get Many:** Retrieve multiple documents based on prompt similarity.
*   **Insert Documents:** Add new documents to the collection (embeddings are generated).
*   **Retrieve Documents (As Vector Store for Chain/Tool):** Provide the store connection for a Retriever sub-node.
*   **Retrieve Documents (As Tool for AI Agent):** Expose the store as a queryable tool for an AI Agent.

### Parameters by Mode

**1. Get Many:**

*   **Qdrant Collection Name:** The name of the Qdrant collection to query.
*   **Embeddings:** Select the Embeddings model sub-node to use for the prompt.
*   **Prompt:** The text query for similarity search.
*   **Limit:** Maximum number of similar documents to return.
*   **(Optional) Metadata Filter:** Filter results based on metadata fields (uses AND logic if multiple filters are applied).

**2. Insert Documents:**

*   **Qdrant Collection Name:** The name of the Qdrant collection to insert into.
*   **Embeddings:** Select the Embeddings model sub-node to use for creating document embeddings.
*   **Text Splitter:** (Optional) Select a Text Splitter sub-node to chunk large documents before embedding.
*   **(Optional) Collection Config:** Provide JSON configuration for creating the Qdrant collection if it doesn't exist. Refer to [Qdrant Collections documentation](https://qdrant.tech/documentation/concepts/collections/).

**3. Retrieve Documents (As Vector Store for Chain/Tool):**

*   **Qdrant Collection:** The name of the Qdrant collection to connect to.
*   **Embeddings:** Select the Embeddings model sub-node (must match the one used for insertion).
*   **(Optional) Metadata Filter:** Filter results based on metadata fields.

**4. Retrieve Documents (As Tool for AI Agent):**

*   **Name:** A descriptive name for the tool (used by the agent).
*   **Description:** Explain the tool's purpose and content to the agent.
*   **Qdrant Collection:** The name of the Qdrant collection to query.
*   **Embeddings:** Select the Embeddings model sub-node (must match the one used for insertion).
*   **Limit:** Maximum number of similar documents to retrieve per query.

## Related resources

*   Refer to [LangChain's Qdrant documentation](https://python.langchain.com/v0.1/docs/integrations/vectorstores/qdrant/) for more information.
*   View n8n's [Advanced AI](https://docs.n8n.io/advanced-ai/) documentation.
*   See the blog post: [Chat with a codebase using Qdrant and N8N](https://qdrant.tech/blog/qdrant-n8n/).
*   Check the [n8n Self-hosted AI Starter Kit](https://github.com/n8n-io/ai-starter-kit) for examples using Qdrant.

## AI glossary

*   **completion**: Completions are the responses generated by a model like GPT.
*   **embeddings**: Numerical representations of text, capturing semantic meaning.
*   **hallucinations**: Hallucination in AI is when an LLM (large language model) mistakenly perceives patterns or objects that don't exist.
*   **vector database**: A database optimized for storing and querying vector embeddings (like Qdrant).
*   **vector store**: A component (like this node) that interfaces with a vector database.

---

## 11.3.5. supabaseVectorStore

# Supabase Vector Store node

Use the Supabase Vector Store node to interact with your vector data stored in a [Supabase](https://supabase.com/) database, which utilizes PostgreSQL with the `pgvector` extension.

This node allows you to insert, update, or retrieve documents (via similarity search) from a specified Supabase table. It can also provide the store connection to a retriever sub-node or connect directly as a tool for an AI Agent.

**Prerequisites:**

*   A Supabase project.
*   The `pgvector` extension enabled in your Supabase database.
*   A table set up for vector storage (see [Supabase vector quickstart](https://supabase.com/docs/guides/ai/quickstarts/vector-database)).
*   A database function for matching documents (e.g., `match_documents` from the quickstart).
*   Supabase credentials (Project URL and Service Role Key) configured in n8n.

**Note on Parameter Resolution in Sub-nodes:** When used as a sub-node or connected to one, expressions within its parameters resolve only based on the *first* incoming item, not for each item individually.

On this page, you'll find usage patterns and node parameters.

## Node Usage Patterns

1.  **Regular Node (Insert/Update/Retrieve):** Use directly in the workflow to insert, update (by ID), or retrieve documents via similarity search from a specified table using the defined match function.
2.  **Direct Tool for AI Agent:** Connect to the `tool` input of an AI Agent node. The agent can then query the Supabase table as one of its available tools.
3.  **Retriever for Chains:** Connect to a `Vector Store Retriever` sub-node, which in turn connects to a chain node (like `Question and Answer Chain`). The retriever fetches relevant documents from the specified Supabase table based on the chain's input.
4.  **Tool for Vector Store Q&A:** Connect to a `Vector Store Question Answer Tool` sub-node, which then connects to an AI Agent. This allows the agent to get summarized answers based on the Supabase table content.

## Node Parameters

### Credentials

Select your configured Supabase credentials.

### Operation Mode

Select the node's function:

*   **Get Many:** Retrieve multiple documents based on prompt similarity.
*   **Insert Documents:** Add new documents to the table (embeddings are generated).
*   **Retrieve Documents (As Vector Store for Chain/Tool):** Provide the store connection for a Retriever sub-node.
*   **Retrieve Documents (As Tool for AI Agent):** Expose the store as a queryable tool for an AI Agent.
*   **Update Documents:** Update existing documents in the table by their ID.

### Parameters by Mode

**1. Get Many:**

*   **Table Name:** The name of the Supabase table containing vectors (e.g., `documents`).
*   **Embeddings:** Select the Embeddings model sub-node to use for the prompt.
*   **Prompt:** The text query for similarity search.
*   **Limit:** Maximum number of similar documents to return.
*   **(Optional) Metadata Filter:** Filter results based on metadata fields (uses AND logic if multiple filters are applied).
*   **(Optional) Query Name:** The name of the database function used for matching (default: `match_documents`).

**2. Insert Documents:**

*   **Table Name:** The name of the Supabase table to insert into (e.g., `documents`).
*   **Embeddings:** Select the Embeddings model sub-node to use for creating document embeddings.
*   **Text Splitter:** (Optional) Select a Text Splitter sub-node to chunk large documents before embedding.

**3. Retrieve Documents (As Vector Store for Chain/Tool):**

*   **Table Name:** The name of the Supabase table to connect to (e.g., `documents`).
*   **Embeddings:** Select the Embeddings model sub-node (must match the one used for insertion).
*   **(Optional) Query Name:** The name of the database function used for matching (default: `match_documents`).
*   **(Optional) Metadata Filter:** Filter results based on metadata fields.

**4. Retrieve Documents (As Tool for AI Agent):**

*   **Name:** A descriptive name for the tool (used by the agent).
*   **Description:** Explain the tool's purpose and content to the agent.
*   **Table Name:** The name of the Supabase table to query (e.g., `documents`).
*   **Embeddings:** Select the Embeddings model sub-node (must match the one used for insertion).
*   **Limit:** Maximum number of similar documents to retrieve per query.
*   **(Optional) Query Name:** The name of the database function used for matching (default: `match_documents`).

**5. Update Documents:**

*   **Table Name:** The name of the Supabase table containing the document (e.g., `documents`).
*   **Embeddings:** Select the Embeddings model sub-node.
*   **ID:** The ID of the vector/document entry to update.

## Related resources

*   Refer to [LangChain's Supabase documentation](https://python.langchain.com/v0.1/docs/integrations/vectorstores/supabase/) for more information.
*   View n8n's [Advanced AI](https://docs.n8n.io/advanced-ai/) documentation.
*   Follow the [Supabase vector quickstart](https://supabase.com/docs/guides/ai/quickstarts/vector-database) for setup.

## AI glossary

*   **completion**: Completions are the responses generated by a model like GPT.
*   **embeddings**: Numerical representations of text, capturing semantic meaning.
*   **hallucinations**: Hallucination in AI is when an LLM (large language model) mistakenly perceives patterns or objects that don't exist.
*   **vector database**: A database optimized for storing and querying vector embeddings (Supabase uses PostgreSQL with pgvector).
*   **vector store**: A component (like this node) that interfaces with a vector database.

---

## 11.3.6. zepVectorStore

# Zep Vector Store node

Use the Zep Vector Store node to interact with vector data stored in a [Zep](https://docs.getzep.com/) collection. Zep is an open-source service for LLM application development, providing long-term memory and vector storage capabilities.

This node allows you to insert documents (creating embeddings), retrieve documents via similarity search, provide the store connection to a retriever sub-node, or connect the store directly as a tool for an AI Agent.

**Prerequisites:**

*   A Zep instance (cloud or self-hosted).
*   Zep credentials (Server URL and optionally API Key) configured in n8n.

**Note on Parameter Resolution in Sub-nodes:** When used as a sub-node or connected to one, expressions within its parameters resolve only based on the *first* incoming item, not for each item individually.

On this page, you'll find usage patterns and node parameters.

## Node Usage Patterns

1.  **Regular Node (Insert/Retrieve):** Use directly in the workflow to insert documents (creating embeddings) into a specified Zep collection or retrieve documents via similarity search using a prompt.
2.  **Direct Tool for AI Agent:** Connect to the `tool` input of an AI Agent node. The agent can then query the Zep collection as one of its available tools.
3.  **Retriever for Chains:** Connect to a `Vector Store Retriever` sub-node, which in turn connects to a chain node (like `Question and Answer Chain`). The retriever fetches relevant documents from the specified Zep collection based on the chain's input.
4.  **Tool for Vector Store Q&A:** Connect to a `Vector Store Question Answer Tool` sub-node, which then connects to an AI Agent. This allows the agent to get summarized answers based on the Zep collection content.

## Node Parameters

### Credentials

Select your configured Zep credentials.

### Operation Mode

Select the node's function:

*   **Get Many:** Retrieve multiple documents based on prompt similarity.
*   **Insert Documents:** Add new documents to the collection (embeddings are generated).
*   **Retrieve Documents (As Vector Store for Chain/Tool):** Provide the store connection for a Retriever sub-node.
*   **Retrieve Documents (As Tool for AI Agent):** Expose the store as a queryable tool for an AI Agent.

### Parameters by Mode

**1. Get Many:**

*   **Collection Name:** The name of the Zep collection to query.
*   **Embeddings:** Select the Embeddings model sub-node to use for the prompt.
*   **Prompt:** The text query for similarity search.
*   **Limit:** Maximum number of similar documents to return.
*   **(Optional) Metadata Filter:** Filter results based on metadata fields (uses AND logic if multiple filters are applied).

**2. Insert Documents:**

*   **Collection Name:** The name of the Zep collection to insert into.
*   **Embeddings:** Select the Embeddings model sub-node to use for creating document embeddings.
*   **Text Splitter:** (Optional) Select a Text Splitter sub-node to chunk large documents before embedding.
*   **(Optional) Embedding Dimensions:** Specify the dimensions for the embeddings (must match query dimensions).
*   **(Optional) Is Auto Embedded:** Disable if embeddings are handled by Zep itself (enabled by default).

**3. Retrieve Documents (As Vector Store for Chain/Tool):**

*   **Collection Name:** The name of the Zep collection to connect to.
*   **Embeddings:** Select the Embeddings model sub-node (must match the one used for insertion).
*   **(Optional) Metadata Filter:** Filter results based on metadata fields.

**4. Retrieve Documents (As Tool for AI Agent):**

*   **Name:** A descriptive name for the tool (used by the agent).
*   **Description:** Explain the tool's purpose and content to the agent.
*   **Collection Name:** The name of the Zep collection to query.
*   **Embeddings:** Select the Embeddings model sub-node (must match the one used for insertion).
*   **Limit:** Maximum number of similar documents to retrieve per query.

## Related resources

*   Refer to [LangChain's Zep documentation](https://python.langchain.com/v0.1/docs/integrations/vectorstores/zep/) for more information.
*   View n8n's [Advanced AI](https://docs.n8n.io/advanced-ai/) documentation.
*   Explore [Zep's documentation](https://docs.getzep.com/).

## AI glossary

*   **completion**: Completions are the responses generated by a model like GPT.
*   **embeddings**: Numerical representations of text, capturing semantic meaning.
*   **hallucinations**: Hallucination in AI is when an LLM (large language model) mistakenly perceives patterns or objects that don't exist.
*   **vector database**: A database optimized for storing and querying vector embeddings (Zep provides this functionality).
*   **vector store**: A component (like this node) that interfaces with a vector database.

---

## 11.4.1. langChainCode

# LangChain Code node

Use the LangChain Code node to execute custom JavaScript/TypeScript code leveraging the LangChain library directly within your n8n workflow. This is useful when specific LangChain functionality isn't available through dedicated n8n nodes.

**Availability:** This node is only available on **self-hosted** n8n instances.

By configuring its input and output connectors, the LangChain Code node can function as a standard workflow node, a root node for a cluster, or a sub-node providing data to another cluster node.

## Node Parameters

### Add Code

This is where you write your custom LangChain code. You must choose one of two modes:

*   **Execute:** Functions similarly to the standard n8n Code node. It takes data from a `main` input, processes it using your LangChain code, and returns the result via a `main` output. This mode requires both `main` input and `main` output connectors to be configured in the **Inputs** and **Outputs** sections.
*   **Supply Data:** Use this mode when the LangChain Code node acts as a sub-node, providing data (like a custom tool, retriever, memory, etc.) to a root node (e.g., an AI Agent or a Chain). This mode requires configuring a non-`main` output connector (e.g., `Tool`, `Retriever`, `Memory`).

**Note:** Unlike the standard n8n Code node, the LangChain Code node **does not support Python**. It executes JavaScript/TypeScript.

**Module Loading:** By default, loading built-in Node.js modules or external npm packages is disabled. Self-hosted users can enable this functionality through environment variables (refer to n8n documentation on enabling modules in code nodes).

### Inputs

Configure the types of input connectors for the node. A `main` input is required for `Execute` mode.

### Outputs

Configure the types of output connectors for the node. A `main` output is required for `Execute` mode. For `Supply Data` mode, configure the appropriate output type (e.g., `Tool`, `Retriever`, `Memory`, `LLM`, `Chat Model`, `Embeddings`, `Text Splitter`, `Output Parser`, `Vector Store`).

## Node Inputs and Outputs Configuration

The flexibility to define inputs and outputs allows the LangChain Code node to adapt to various roles within a workflow:

*   **Standard Node:** Configure `main` input and `main` output (use `Execute` mode).
*   **Root Node:** Configure specific sub-node inputs (e.g., `LLM`, `Memory`, `Tools`) and potentially a `main` output.
*   **Sub-node:** Configure a `main` input (optional, depending on logic) and a specific non-`main` output (e.g., `Tool`, `Retriever`) (use `Supply Data` mode).

## Built-in Methods

n8n provides several [convenience methods](https://docs.n8n.io/code/builtin/langchain-methods/) to simplify common tasks within the LangChain Code node environment.

## Related resources

*   View n8n's [Advanced AI](https://docs.n8n.io/advanced-ai/) documentation.
*   Explore [LangChain concepts in n8n](https://docs.n8n.io/advanced-ai/langchain/langchain-n8n/).
*   Refer to the main [LangChain JS/TS documentation](https://js.langchain.com/docs/).

## AI glossary

*   **LangChain**: A framework for developing applications powered by language models.
*   **Root Node**: The main node in an n8n cluster node setup (e.g., AI Agent, Basic LLM Chain).
*   **Sub-node**: A node that provides specific functionality (like memory, tools, data retrieval) to a root node within a cluster.

---

